"""
Îç∞Ïù¥ÌÑ∞ Ï∫êÏã± Ïú†Ìã∏Î¶¨Ìã∞
1Î∂ÑÎ¥â Îç∞Ïù¥ÌÑ∞Î•º ÌååÏùº Í∏∞Î∞òÏúºÎ°ú Ï∫êÏã±ÌïòÏó¨ DB Î∂ÄÌïò Í∞êÏÜå
"""
import os
import pickle
import pandas as pd
from pathlib import Path
from typing import Optional
from utils.logger import setup_logger


class DataCache:
    """ÌååÏùº Í∏∞Î∞ò Îç∞Ïù¥ÌÑ∞ Ï∫êÏãú Í¥ÄÎ¶¨Ïûê"""
    
    def __init__(self, cache_dir: str = "cache/minute_data"):
        self.logger = setup_logger(__name__)
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def _get_cache_file(self, stock_code: str, date_str: str) -> Path:
        """Ï∫êÏãú ÌååÏùº Í≤ΩÎ°ú ÏÉùÏÑ±"""
        return self.cache_dir / f"{stock_code}_{date_str}.pkl"
    
    def has_data(self, stock_code: str, date_str: str) -> bool:
        """Ï∫êÏãúÎêú Îç∞Ïù¥ÌÑ∞ Ï°¥Ïû¨ Ïó¨Î∂Ä ÌôïÏù∏"""
        cache_file = self._get_cache_file(stock_code, date_str)
        return cache_file.exists()
    
    def save_data(self, stock_code: str, date_str: str, df_minute: pd.DataFrame) -> bool:
        """1Î∂ÑÎ¥â Îç∞Ïù¥ÌÑ∞Î•º ÌååÏùºÎ°ú Ï∫êÏã±"""
        try:
            if df_minute is None or df_minute.empty:
                return True
            
            cache_file = self._get_cache_file(stock_code, date_str)
            
            # DataFrameÏùÑ pickleÎ°ú ÏïïÏ∂ï Ï†ÄÏû•
            with open(cache_file, 'wb') as f:
                pickle.dump(df_minute, f, protocol=pickle.HIGHEST_PROTOCOL)
            
            self.logger.info(f"üíæ [{stock_code}] 1Î∂ÑÎ¥â Îç∞Ïù¥ÌÑ∞ Ï∫êÏãú Ï†ÄÏû• ({len(df_minute)}Í∞ú)")
            return True
            
        except Exception as e:
            self.logger.error(f"Ï∫êÏãú Ï†ÄÏû• Ïã§Ìå® ({stock_code}, {date_str}): {e}")
            return False
    
    def load_data(self, stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
        """Ï∫êÏãúÎêú 1Î∂ÑÎ¥â Îç∞Ïù¥ÌÑ∞ Î°úÎìú"""
        try:
            cache_file = self._get_cache_file(stock_code, date_str)
            
            if not cache_file.exists():
                return None
            
            with open(cache_file, 'rb') as f:
                df_minute = pickle.load(f)
            
            self.logger.info(f"üìÅ [{stock_code}] Ï∫êÏãúÏóêÏÑú 1Î∂ÑÎ¥â Îç∞Ïù¥ÌÑ∞ Î°úÎìú ({len(df_minute)}Í∞ú)")
            return df_minute
            
        except Exception as e:
            self.logger.error(f"Ï∫êÏãú Î°úÎìú Ïã§Ìå® ({stock_code}, {date_str}): {e}")
            return None
    
    def clear_cache(self, stock_code: str = None, date_str: str = None):
        """Ï∫êÏãú Ï†ïÎ¶¨"""
        try:
            if stock_code and date_str:
                # ÌäπÏ†ï ÌååÏùº ÏÇ≠Ï†ú
                cache_file = self._get_cache_file(stock_code, date_str)
                if cache_file.exists():
                    cache_file.unlink()
                    self.logger.info(f"Ï∫êÏãú ÌååÏùº ÏÇ≠Ï†ú: {cache_file}")
            else:
                # Ï†ÑÏ≤¥ Ï∫êÏãú ÏÇ≠Ï†ú
                for cache_file in self.cache_dir.glob("*.pkl"):
                    cache_file.unlink()
                self.logger.info(f"Ï†ÑÏ≤¥ Ï∫êÏãú Ï†ïÎ¶¨ ÏôÑÎ£å: {self.cache_dir}")
                
        except Exception as e:
            self.logger.error(f"Ï∫êÏãú Ï†ïÎ¶¨ Ïã§Ìå®: {e}")
    
    def get_cache_size(self) -> dict:
        """Ï∫êÏãú ÌÅ¨Í∏∞ Ï†ïÎ≥¥"""
        try:
            total_files = 0
            total_size = 0
            
            for cache_file in self.cache_dir.glob("*.pkl"):
                total_files += 1
                total_size += cache_file.stat().st_size
            
            return {
                'total_files': total_files,
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'cache_dir': str(self.cache_dir)
            }
            
        except Exception as e:
            self.logger.error(f"Ï∫êÏãú ÌÅ¨Í∏∞ ÌôïÏù∏ Ïã§Ìå®: {e}")
            return {'total_files': 0, 'total_size_mb': 0, 'cache_dir': str(self.cache_dir)}
