"""
ì‹¤ë°ì´í„° ê¸°ë°˜ ë§¤ë§¤ì‹ í˜¸(ëˆŒë¦¼ëª©/3ë¶„ë´‰) ì¬í˜„ ë¦¬í¬íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš© ì˜ˆ (Windows PowerShell):
  python utils\signal_replay.py --date 20250808 \
    --codes 034230,078520,107600,214450 \
    --times "034230=14:39;078520=11:33;107600=11:24,11:27,14:51;214450=12:00,14:39" \
    --export csv

ë™ì‘:
- ê° ì¢…ëª©ì˜ ë‹¹ì¼ 1ë¶„ë´‰(09:00~15:30)ì„ ì‹¤ë°ì´í„°ë¡œ ì¡°íšŒ
- 3ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜ í›„ PullbackCandlePattern.generate_trading_signals ê³„ì‚°
- ì§€ì • ì‹œê°ì—ì„œ ë§¤ìˆ˜ì‹ í˜¸(buy_pullback_pattern / buy_bisector_recovery) ON/OFF í™•ì¸
- OFFë©´ í•µì‹¬ ë¯¸ì¶©ì¡± ì¡°ê±´(ì €ê±°ë˜ 3ë´‰, íšŒë³µì–‘ë´‰, ê±°ë˜ëŸ‰ íšŒë³µ, ì´ë“±ë¶„ì„  ì§€ì§€/íšŒë³µ)ì„ ìš”ì•½

ì£¼ì˜:
- ë”ë¯¸ ë°ì´í„° ì‚¬ìš© ì—†ìŒ. KIS API ì„¤ì •ì´ ìœ íš¨í•´ì•¼ í•©ë‹ˆë‹¤.
- ì „ëµì€ ëˆŒë¦¼ëª©ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì¬ë§¤ìˆ˜ ì •ì±…ì—ëŠ” ì˜í–¥ ì£¼ì§€ ì•ŠìŠµë‹ˆë‹¤(ë¦¬í¬íŒ… ì „ìš©).
"""

from __future__ import annotations

import argparse
import asyncio
from dataclasses import dataclass
from typing import Dict, List, Tuple, Optional
import sys
import os

import pandas as pd

from utils.logger import setup_logger
from visualization.data_processor import DataProcessor
from core.indicators.pullback_candle_pattern import PullbackCandlePattern
from core.indicators.bisector_line import BisectorLine
# ì‹¤ì „ íë¦„ ê¸°ì¤€: í˜„ì¬ ë¦¬í”Œë ˆì´ëŠ” ëˆŒë¦¼ëª©(3ë¶„)ë§Œ ì‚¬ìš©í•˜ì—¬ ì‹¤ì „ ê·œì¹™ì„ ì¬í˜„í•©ë‹ˆë‹¤.
from api.kis_api_manager import KISAPIManager


try:
    # PowerShell cp949 ì½˜ì†”ì—ì„œ ì´ëª¨ì§€/UTF-8 ë¡œê·¸ ì¶œë ¥ ì˜¤ë¥˜ ë°©ì§€
    sys.stdout.reconfigure(encoding="utf-8")
    sys.stderr.reconfigure(encoding="utf-8")
except Exception:
    pass

logger = setup_logger(__name__)


@dataclass
class TimeCheck:
    stock_code: str
    check_times: List[str]  # ["HH:MM", ...]


def parse_times_mapping(arg_value: str) -> Dict[str, List[str]]:
    """íŒŒë¼ë¯¸í„° --times íŒŒì‹±
    í˜•ì‹: "034230=14:39;078520=11:33;107600=11:24,11:27,14:51;214450=12:00,14:39"
    ë°˜í™˜: {"034230": ["14:39"], "078520": ["11:33"], ...}
    """
    mapping: Dict[str, List[str]] = {}
    if not arg_value:
        return mapping
    for part in arg_value.split(";"):
        part = part.strip()
        if not part:
            continue
        if "=" not in part:
            continue
        code, times_str = part.split("=", 1)
        code = code.strip()
        times_list = [t.strip() for t in times_str.split(",") if t.strip()]
        if code and times_list:
            mapping[code] = times_list
    return mapping


def floor_to_3min(ts: pd.Timestamp) -> pd.Timestamp:
    """ì£¼ì–´ì§„ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ 3ë¶„ ê²½ê³„ë¡œ ë‚´ë¦¼(floor)í•œë‹¤."""
    return ts.floor("3T")


def locate_row_for_time(df_3min: pd.DataFrame, target_date: str, hhmm: str) -> Optional[int]:
    """3ë¶„ë´‰ DataFrameì—ì„œ íŠ¹ì • HH:MM ë¼ë²¨ì˜ í–‰ ì¸ë±ìŠ¤ë¥¼ ì°¾ëŠ”ë‹¤.
    - DataFrameì€ 'datetime' ì»¬ëŸ¼ì„ ê°€ì ¸ì•¼ í•œë‹¤(visualization.DataProcessor ê¸°ì¤€).
    - ì—†ìœ¼ë©´ None.
    """
    if df_3min is None or df_3min.empty or "datetime" not in df_3min.columns:
        return None
    try:
        # target_date(YYYYMMDD) + HH:MM:00 â†’ floor 3ë¶„ìœ¼ë¡œ ë³´ì •
        date_str = f"{target_date[:4]}-{target_date[4:6]}-{target_date[6:8]}"
        target_ts = pd.Timestamp(f"{date_str} {hhmm}:00")
        target_floor = floor_to_3min(target_ts)
        # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë¼ë²¨ ìš°ì„ 
        matches = df_3min.index[df_3min["datetime"] == target_floor].tolist()
        if matches:
            return matches[0]
        # ê·¼ì ‘(Â±2ë¶„) ê²€ìƒ‰: ê°€ì¥ ê°€ê¹Œìš´ ì¸ë±ìŠ¤ ì„ íƒ
        deltas = (df_3min["datetime"] - target_ts).abs()
        nearest_idx = int(deltas.idxmin()) if len(deltas) > 0 else None
        if nearest_idx is not None:
            min_delta_sec = abs((df_3min.loc[nearest_idx, "datetime"] - target_ts).total_seconds())
            if min_delta_sec <= 120:  # 2ë¶„ ì´ë‚´ë©´ í—ˆìš©
                return nearest_idx
        return None
    except Exception:
        return None


def analyze_unmet_conditions_at(
    df_3min: pd.DataFrame,
    idx: int
) -> List[str]:
    """í•´ë‹¹ 3ë¶„ë´‰ ì¸ë±ìŠ¤ì—ì„œ ëˆŒë¦¼ëª© ë§¤ìˆ˜ ì¡°ê±´ ì¤‘ ë¬´ì—‡ì´ ë¯¸ì¶©ì¡±ì¸ì§€ ìš”ì•½.
    PullbackCandlePattern.generate_trading_signals ë‚´ë¶€ ì£¼ìš” ì¡°ê±´ì„ ì¬í˜„í•œë‹¤.
    """
    unmet: List[str] = []
    try:
        if idx is None or idx < 0 or idx >= len(df_3min):
            return ["ì¸ë±ìŠ¤ ë²”ìœ„ ì˜¤ë¥˜"]

        required_cols = ["open", "high", "low", "close", "volume"]
        if not all(col in df_3min.columns for col in required_cols):
            return ["í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½"]

        # ì´ë“±ë¶„ì„  ê³„ì‚°
        bisector_line = BisectorLine.calculate_bisector_line(df_3min["high"], df_3min["low"]) if "high" in df_3min.columns and "low" in df_3min.columns else None

        retrace_lookback = 3
        low_vol_ratio = 0.25
        stop_leeway = 0.002  # ì‚¬ìš©í•˜ì§„ ì•Šì§€ë§Œ ì›ë³¸ íŒŒë¼ë¯¸í„° ìœ ì§€

        # í˜„ì¬ ìº”ë“¤
        row = df_3min.iloc[idx]
        current_open = float(row["open"]) if pd.notna(row["open"]) else None
        current_close = float(row["close"]) if pd.notna(row["close"]) else None
        current_volume = float(row["volume"]) if pd.notna(row["volume"]) else None

        # ì´ë“±ë¶„ì„  ê´€ë ¨
        bl = float(bisector_line.iloc[idx]) if bisector_line is not None and pd.notna(bisector_line.iloc[idx]) else None
        above_bisector = (bl is not None) and (current_close is not None) and (current_close >= bl)
        crosses_bisector_up = (bl is not None) and (current_open is not None) and (current_close is not None) and (current_open <= bl <= current_close)

        is_bullish = (current_close is not None) and (current_open is not None) and (current_close > current_open)

        # ìµœê·¼ 10ë´‰ í‰ê·  ê±°ë˜ëŸ‰
        recent_start = max(0, idx - 10)
        avg_recent_vol = float(df_3min["volume"].iloc[recent_start:idx].mean()) if idx > 0 else 0.0

        # ì €ê±°ë˜ 3ë´‰ êµ¬ê°„(ì§ì „ 3ê°œ)
        if idx >= retrace_lookback:
            window = df_3min.iloc[idx - retrace_lookback:idx]
            # rolling baseline(ìµœê·¼ 50ë´‰ ìµœëŒ€)
            baseline_now = float(df_3min["volume"].iloc[max(0, idx - 50):idx + 1].max()) if idx > 0 else float(df_3min["volume"].iloc[:1].max())
            low_volume_all = bool((window["volume"] < baseline_now * low_vol_ratio).all()) if baseline_now > 0 else False
            # ì—°ì† í•˜ë½
            close_diff = window["close"].diff().fillna(0)
            # ìµœê·¼ 3ë´‰ ëª¨ë‘ ì „ë´‰ ëŒ€ë¹„ í•˜ë½ì´ì–´ì•¼ í•¨: ë‘ ê°œì˜ ìœ íš¨ ë¹„êµ(-2, -1)
            downtrend_all = bool((close_diff.iloc[1:] < 0).all()) if len(close_diff) >= 2 else False
            is_low_volume_retrace = low_volume_all and downtrend_all
        else:
            is_low_volume_retrace = False

        # ê±°ë˜ëŸ‰ íšŒë³µ
        max_low_vol = float(df_3min["volume"].iloc[max(0, idx - retrace_lookback):idx].max()) if idx > 0 else 0.0
        volume_recovers = (current_volume is not None) and (
            (current_volume > max_low_vol) or (current_volume > avg_recent_vol)
        )

        # ë¯¸ì¶©ì¡± í•­ëª© ê¸°ë¡
        # 1) ì €ê±°ë˜ ì¡°ì • 3ë´‰
        if not is_low_volume_retrace:
            unmet.append("ì €ê±°ë˜ í•˜ë½ 2ë´‰ ë¯¸ì¶©ì¡±")
        # 2) íšŒë³µ ì–‘ë´‰
        if not is_bullish:
            unmet.append("íšŒë³µ ì–‘ë´‰ ì•„ë‹˜")
        # 3) ê±°ë˜ëŸ‰ íšŒë³µ
        if not volume_recovers:
            unmet.append("ê±°ë˜ëŸ‰ íšŒë³µ ë¯¸ì¶©ì¡±")
        # 4) ì´ë“±ë¶„ì„  ì§€ì§€/íšŒë³µ
        if not (above_bisector or crosses_bisector_up):
            unmet.append("ì´ë“±ë¶„ì„  ì§€ì§€/íšŒë³µ ë¯¸ì¶©ì¡±")

        return unmet
    except Exception as e:
        return [f"ë¶„ì„ ì˜¤ë¥˜: {e}"]


async def fetch_and_prepare_3min(stock_code: str, target_date: str) -> Optional[pd.DataFrame]:
    """ì‹¤ë°ì´í„° 1ë¶„ë´‰ì„ ì¡°íšŒ í›„ 3ë¶„ë´‰ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜."""
    dp = DataProcessor()
    base_1min = await dp.get_historical_chart_data(stock_code, target_date)
    if base_1min is None or base_1min.empty:
        logger.error(f"{stock_code} {target_date} 1ë¶„ë´‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
        return None
    df_3min = dp.get_timeframe_data(stock_code, target_date, "3min", base_data=base_1min)
    if df_3min is None or df_3min.empty:
        logger.error(f"{stock_code} {target_date} 3ë¶„ë´‰ ë³€í™˜ ì‹¤íŒ¨")
        return None
    return df_3min


def evaluate_signals_at_times(df_3min: pd.DataFrame, target_date: str, times: List[str]) -> List[Dict[str, object]]:
    """ì§€ì • ì‹œê°ë“¤ì—ì„œ ëˆŒë¦¼ëª© ë§¤ìˆ˜ì‹ í˜¸ ON/OFFì™€ ë¯¸ì¶©ì¡± ì‚¬ìœ ë¥¼ í‰ê°€."""
    results: List[Dict[str, object]] = []
    if df_3min is None or df_3min.empty:
        for t in times:
            results.append({
                "time": t,
                "has_signal": False,
                "signal_types": [],
                "unmet_conditions": ["ë°ì´í„° ì—†ìŒ"],
            })
        return results

    # ì‹ í˜¸ ì „ì²´ ê³„ì‚°(3ë¶„ë´‰)
    signals = PullbackCandlePattern.generate_trading_signals(df_3min)
    for t in times:
        row_idx = locate_row_for_time(df_3min, target_date, t)
        if row_idx is None:
            results.append({
                "time": t,
                "has_signal": False,
                "signal_types": [],
                "unmet_conditions": ["ì‹œê° ë§¤ì¹­ ì‹¤íŒ¨"],
            })
            continue

        buy1 = bool(signals.get("buy_pullback_pattern", pd.Series([False]*len(df_3min))).iloc[row_idx]) if not signals.empty else False
        buy2 = bool(signals.get("buy_bisector_recovery", pd.Series([False]*len(df_3min))).iloc[row_idx]) if not signals.empty else False
        has_signal = buy1 or buy2
        signal_types = []
        if buy1:
            signal_types.append("buy_pullback_pattern")
        if buy2:
            signal_types.append("buy_bisector_recovery")

        if has_signal:
            results.append({
                "time": t,
                "has_signal": True,
                "signal_types": signal_types,
                "unmet_conditions": [],
            })
        else:
            unmet = analyze_unmet_conditions_at(df_3min, row_idx)
            results.append({
                "time": t,
                "has_signal": False,
                "signal_types": [],
                "unmet_conditions": unmet,
            })

    return results


def list_all_buy_signals(df_3min: pd.DataFrame) -> List[Dict[str, object]]:
    """í•´ë‹¹ 3ë¶„ë´‰ ì „ì²´ì—ì„œ ë°œìƒí•œ ë§¤ìˆ˜ ì‹ í˜¸ ì‹œê°/ìœ í˜• ë¦¬ìŠ¤íŠ¸.

    ì‹¤ì „ ê¸°ì¤€: ëˆŒë¦¼ëª©(3ë¶„) ì‹ í˜¸ë§Œ ì‚¬ìš© (consolidation breakout ì œì™¸)
    """
    out: List[Dict[str, object]] = []
    if df_3min is None or df_3min.empty or 'datetime' not in df_3min.columns:
        return out
    sig = PullbackCandlePattern.generate_trading_signals(df_3min)
    if sig is None or sig.empty:
        sig = pd.DataFrame(index=df_3min.index)
    has_pb = sig.get('buy_pullback_pattern', pd.Series([False]*len(df_3min)))
    has_rc = sig.get('buy_bisector_recovery', pd.Series([False]*len(df_3min)))
    for i in range(len(df_3min)):
        pb = bool(has_pb.iloc[i])
        rc = bool(has_rc.iloc[i])
        if not (pb or rc):
            continue
        ts = df_3min['datetime'].iloc[i]
        hhmm = pd.Timestamp(ts).strftime('%H:%M')
        types = []
        if pb:
            types.append('pullback')
        if rc:
            types.append('bisector_recovery')
        out.append({'time': hhmm, 'types': '+'.join(types)})
    return out


def simulate_trades(df_3min: pd.DataFrame) -> List[Dict[str, object]]:
    """ì‹¤ì „(_execute_trading_decision) ê¸°ì¤€ì— ë§ì¶˜ ëˆŒë¦¼ëª©(3ë¶„) ì²´ê²° ì‹œë®¬ë ˆì´ì…˜.

    ê·œì¹™(ì‹¤ì „ ê·¼ì‚¬):
    - ë§¤ìˆ˜: buy_pullback_pattern ë˜ëŠ” buy_bisector_recoveryê°€ Trueì¼ ë•Œ ì§„ì…
      â€¢ ì²´ê²°ê°€: ì‹ í˜¸ ìº”ë“¤ì˜ ì ˆë°˜ê°€(half: low + (high-low)*0.5), ì‹¤íŒ¨ ì‹œ í•´ë‹¹ ìº”ë“¤ ì¢…ê°€
    - ë§¤ë„ ìš°ì„ ìˆœìœ„: (1) ê³µí†µ ìµœëŒ€ì†ì‹¤ -1.0% â†’ (2) ì†ì ˆ(ì´ë“±ë¶„ì„  -0.2%, ì§€ì§€ì €ì  ì´íƒˆ, ì§„ì…ì €ê°€ -0.2%) â†’ (3) ìµì ˆ +1.5%
    - ì¢…ê°€ ì²´ê²° ê°€ì •, ë³µìˆ˜ ë§¤ë§¤ í—ˆìš©, ëê¹Œì§€ ë³´ìœ  ì‹œ EOD ì²­ì‚°
    """
    trades: List[Dict[str, object]] = []
    if df_3min is None or df_3min.empty or 'datetime' not in df_3min.columns:
        return trades
    sig = PullbackCandlePattern.generate_trading_signals(df_3min)
    if sig is None or sig.empty:
        sig = pd.DataFrame(index=df_3min.index)

    closes = pd.to_numeric(df_3min['close'], errors='coerce')
    in_pos = False
    entry_price = None
    entry_time = None
    entry_type = None
    entry_low = None

    # ì•ˆì „: ë¶ˆë¦¬ì–¸ ì‹œë¦¬ì¦ˆ í™•ë³´
    buy_pb = sig.get('buy_pullback_pattern', pd.Series([False]*len(df_3min)))
    buy_rc = sig.get('buy_bisector_recovery', pd.Series([False]*len(df_3min)))
    # ë§¤ë„ëŠ” ì‹¤ì „ê³¼ ë™ì¼í•˜ê²Œ ì§ì ‘ê³„ì‚° API ì‚¬ìš©

    for i in range(len(df_3min)):
        ts = df_3min['datetime'].iloc[i]
        hhmm = pd.Timestamp(ts).strftime('%H:%M')
        c = float(closes.iloc[i]) if pd.notna(closes.iloc[i]) else None
        if c is None:
            continue

        if not in_pos:
            if bool(buy_pb.iloc[i]) or bool(buy_rc.iloc[i]):
                in_pos = True
                # ì‹¤ì „ ê·¼ì‚¬: ì ˆë°˜ê°€ ì²´ê²° ì‹œë„ â†’ ì‹¤íŒ¨ ì‹œ ì¢…ê°€
                try:
                    hi = float(df_3min['high'].iloc[i])
                    lo = float(df_3min['low'].iloc[i])
                    half = lo + (hi - lo) * 0.5
                    entry_price = half if (half > 0 and lo <= half <= hi) else c
                except Exception:
                    entry_price = c
                entry_time = hhmm
                try:
                    entry_low = float(df_3min['low'].iloc[i])
                except Exception:
                    entry_low = None
                if bool(buy_pb.iloc[i]):
                    entry_type = 'pullback'
                elif bool(buy_rc.iloc[i]):
                    entry_type = 'bisector_recovery'
        else:
            exit_reason = None
            # (1) ê³µí†µ ìµœëŒ€ì†ì‹¤ -1.0%
            if entry_price is not None and c <= entry_price * (1.0 - 0.010):
                exit_reason = 'max_loss_1_0pct'
            else:
                # (2) ì†ì ˆ ì¡°ê±´: ì´ë“±ë¶„ì„  0.2% ì´íƒˆ / ì§€ì§€ì €ì  ì´íƒˆ / ì§„ì…ì €ê°€ 0.2% ì´íƒˆ
                try:
                    sell_sig = PullbackCandlePattern.generate_sell_signals(df_3min.iloc[:i+1], entry_low=entry_low)
                except Exception:
                    sell_sig = pd.DataFrame(index=df_3min.index)
                if not sell_sig.empty:
                    if bool(sell_sig.get('sell_bisector_break', pd.Series([False]*len(df_3min))).iloc[i]):
                        exit_reason = 'sell_bisector_break'
                    elif bool(sell_sig.get('sell_support_break', pd.Series([False]*len(df_3min))).iloc[i]):
                        exit_reason = 'sell_support_break'
                    elif bool(sell_sig.get('stop_entry_low_break', pd.Series([False]*len(df_3min))).iloc[i]):
                        exit_reason = 'stop_entry_low_break'
            # (3) ìµì ˆ +1.5%
            if exit_reason is None and entry_price is not None and c >= entry_price * (1.0 + 0.015):
                exit_reason = 'take_profit_1_5pct'

            if exit_reason is not None:
                profit = (c - entry_price) / entry_price * 100.0 if entry_price and entry_price > 0 else 0.0
                trades.append({
                    'buy_time': entry_time,
                    'buy_type': entry_type,
                    'buy_price': entry_price,
                    'sell_time': hhmm,
                    'sell_reason': exit_reason,
                    'sell_price': c,
                    'profit_rate': profit,
                })
                in_pos = False
                entry_price = None
                entry_time = None
                entry_type = None
                entry_low = None

    # EOD ì²­ì‚°
    if in_pos and entry_price is not None:
        last_ts = df_3min['datetime'].iloc[-1]
        last_hhmm = pd.Timestamp(last_ts).strftime('%H:%M')
        last_close = float(closes.iloc[-1]) if pd.notna(closes.iloc[-1]) else entry_price
        profit = (last_close - entry_price) / entry_price * 100.0 if entry_price and entry_price > 0 else 0.0
        trades.append({
            'buy_time': entry_time,
            'buy_type': entry_type,
            'buy_price': entry_price,
            'sell_time': last_hhmm,
            'sell_reason': 'EOD',
            'sell_price': last_close,
            'profit_rate': profit,
        })

    return trades


def print_report(stock_code: str, target_date: str, evaluations: List[Dict[str, object]]):
    """ì½˜ì†” ìš”ì•½ ì¶œë ¥."""
    print(f"\n=== {stock_code} - {target_date} ëˆŒë¦¼ëª©(3ë¶„) ì‹ í˜¸ ì¬í˜„ ===")
    for item in evaluations:
        t = item["time"]
        if item["has_signal"]:
            sig = ",".join(item["signal_types"]) if item["signal_types"] else "(ì¢…ë¥˜ ë¯¸ìƒ)"
            print(f"  {t} â†’ ON [{sig}]")
        else:
            reasons = ", ".join(item["unmet_conditions"]) if item["unmet_conditions"] else "(ì‚¬ìœ  ë¯¸ìƒ)"
            print(f"  {t} â†’ OFF  (ë¯¸ì¶©ì¡±: {reasons})")


def to_csv_rows(stock_code: str, target_date: str, evaluations: List[Dict[str, object]]) -> List[Dict[str, object]]:
    rows: List[Dict[str, object]] = []
    for item in evaluations:
        rows.append({
            "stock_code": stock_code,
            "date": target_date,
            "time": item["time"],
            "has_signal": item["has_signal"],
            "signal_types": ",".join(item["signal_types"]) if item["signal_types"] else "",
            "unmet_conditions": ", ".join(item["unmet_conditions"]) if item["unmet_conditions"] else "",
        })
    return rows


async def run(date_str: str, codes: List[str], times_map: Dict[str, List[str]]) -> Tuple[List[Dict[str, object]], Dict[str, List[Dict[str, object]]], Dict[str, List[Dict[str, object]]]]:
    """ë©”ì¸ ì‹¤í–‰ ì½”ë£¨í‹´."""
    all_rows: List[Dict[str, object]] = []
    all_signals: Dict[str, List[Dict[str, object]]] = {}
    all_trades: Dict[str, List[Dict[str, object]]] = {}
    for code in codes:
        try:
            df_3min = await fetch_and_prepare_3min(code, date_str)
            evals = evaluate_signals_at_times(df_3min, date_str, times_map.get(code, []))
            print_report(code, date_str, evals)
            all_rows.extend(to_csv_rows(code, date_str, evals))
            # ì „ì²´ ë§¤ìˆ˜ì‹ í˜¸ ì¶”ì¶œ
            signals_full = list_all_buy_signals(df_3min) if df_3min is not None else []
            all_signals[code] = signals_full
            # ì²´ê²° ì‹œë®¬ë ˆì´ì…˜
            trades = simulate_trades(df_3min) if df_3min is not None else []
            all_trades[code] = trades
        except Exception as e:
            logger.error(f"{code} ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # ì‹¤íŒ¨í•œ ì¢…ëª©ë„ í‘œì— ê¸°ë¡
            for t in times_map.get(code, []):
                all_rows.append({
                    "stock_code": code,
                    "date": date_str,
                    "time": t,
                    "has_signal": False,
                    "signal_types": "",
                    "unmet_conditions": f"ì—ëŸ¬: {e}",
                })
            all_signals[code] = []
            all_trades[code] = []
    return all_rows, all_signals, all_trades


def main():
    parser = argparse.ArgumentParser(description="ëˆŒë¦¼ëª©(3ë¶„) ë§¤ìˆ˜ì‹ í˜¸ ì¬í˜„ ë¦¬í¬íŠ¸")
    parser.add_argument("--date", required=False, default=None, help="ëŒ€ìƒ ë‚ ì§œ (YYYYMMDD)")
    parser.add_argument("--codes", required=False, default=None, help="ì¢…ëª©ì½”ë“œ ì½¤ë§ˆêµ¬ë¶„ ì˜ˆ: 034230,078520")
    parser.add_argument("--times", required=False, default=None, help="ì¢…ëª©ë³„ í™•ì¸ì‹œê° ë§¤í•‘ ì˜ˆ: 034230=14:39;078520=11:33")
    parser.add_argument("--export", choices=["csv", "txt"], default=None, help="ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (csv|txt)")
    parser.add_argument("--csv-path", default="signal_replay.csv", help="CSV ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: signal_replay.csv)")
    parser.add_argument("--txt-path", default="signal_replay.txt", help="TXT ì €ì¥ ê²½ë¡œ (ê¸°ë³¸: signal_replay.txt)")

    args = parser.parse_args()

    def normalize_code(code: str) -> str:
        return str(code).strip().zfill(6)

    # ê¸°ë³¸ê°’ (ìš”ì²­í•˜ì‹  2025-08-08, 4ê°œ ì¢…ëª©/ì‹œê°)
    DEFAULT_DATE = "20250812"
    DEFAULT_CODES = "023160,023790,026040,033340,044490,054300,054540,108490,240810,419050,452160"
    DEFAULT_TIMES = "034230=14:39;078520=11:33,11:36,11:39;107600=11:24,11:27,14:51;214450=12:00,14:39;073010=10:30,10:33,10:36,10:39"

    date_str: str = (args.date or DEFAULT_DATE).strip()
    codes_input = args.codes or DEFAULT_CODES
    times_input = args.times or DEFAULT_TIMES

    codes: List[str] = [normalize_code(c) for c in codes_input.split(",") if str(c).strip()]
    # ì¤‘ë³µ ì œê±°(ì…ë ¥ ìˆœì„œ ìœ ì§€)
    codes = list(dict.fromkeys(codes))
    raw_times_map: Dict[str, List[str]] = parse_times_mapping(times_input)
    # í‚¤ë„ 6ìë¦¬ë¡œ ì •ê·œí™”
    times_map: Dict[str, List[str]] = {normalize_code(k): v for k, v in raw_times_map.items()}

    # ì½”ë“œ ì§‘í•©: DEFAULT_CODES + DEFAULT_TIMESì— ì–¸ê¸‰ëœ ì¢…ëª©ë“¤ì˜ í•©ì§‘í•©(ìˆœì„œ: codes â†’ times)
    codes_union: List[str] = list(codes)
    for k in times_map.keys():
        if k not in codes_union:
            codes_union.append(k)
    # ëˆ„ë½ëœ ì¢…ëª© í‚¤ì— ëŒ€í•´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë³´ì •
    for c in codes_union:
        times_map.setdefault(c, [])

    logger.info(f"ëŒ€ìƒ ë‚ ì§œ: {date_str}")
    logger.info(f"ëŒ€ìƒ ì¢…ëª©: {codes_union}")
    logger.info(f"ì‹œê° ë§¤í•‘: {times_map}")

    # KIS API ì¸ì¦ ì„ í–‰ (ì‹¤ë°ì´í„° ì¡°íšŒ í•„ìš”)
    api_manager = KISAPIManager()
    if not api_manager.initialize():
        print("\nâŒ KIS API ì¸ì¦/ì´ˆê¸°í™” ì‹¤íŒ¨. key.ini/í™˜ê²½ì„¤ì • í™•ì¸ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        sys.exit(1)

    rows, all_signals, all_trades = asyncio.run(run(date_str, codes_union, times_map))

    if args.export == "csv":
        try:
            df = pd.DataFrame(rows)
            df.to_csv(args.csv_path, index=False, encoding="utf-8-sig")
            print(f"\nğŸ“„ CSV ì €ì¥ ì™„ë£Œ: {args.csv_path} ({len(df)}í–‰)")
        except Exception as e:
            print(f"\nâŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")
    elif args.export == "txt":
        try:
            # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í•‘í•˜ì—¬ í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ êµ¬ì„± (ì½”ë“œ ìˆœì„œ ìœ ì§€)
            from collections import defaultdict
            code_to_rows = defaultdict(list)
            for r in rows:
                code_to_rows[r.get("stock_code", "")] .append(r)

            lines: list[str] = []
            for code in codes_union:
                lines.append(f"=== {code} - {date_str} ëˆŒë¦¼ëª©(3ë¶„) ì‹ í˜¸ ì¬í˜„ ===")
                # ì…ë ¥ ì‹œê° ìˆœì„œë¥¼ ìœ ì§€í•˜ì—¬ ì¶œë ¥
                for t in times_map.get(code, []):
                    # í•´ë‹¹ ì‹œê°ì˜ ë ˆì½”ë“œ ì°¾ê¸°
                    rec = next((x for x in code_to_rows.get(code, []) if x.get("time") == t), None)
                    if rec is None:
                        lines.append(f"  {t} â†’ OFF  (ë¯¸ì¶©ì¡±: ì‹œê° ë§¤ì¹­ ì‹¤íŒ¨)")
                        continue
                    if bool(rec.get("has_signal", False)):
                        sig = rec.get("signal_types", "")
                        sig_disp = sig if sig else "(ì¢…ë¥˜ ë¯¸ìƒ)"
                        lines.append(f"  {t} â†’ ON [{sig_disp}]")
                    else:
                        reasons = rec.get("unmet_conditions", "")
                        reasons_disp = reasons if reasons else "(ì‚¬ìœ  ë¯¸ìƒ)"
                        lines.append(f"  {t} â†’ OFF  (ë¯¸ì¶©ì¡±: {reasons_disp})")
                # ì „ì²´ ë§¤ë§¤ì‹ í˜¸ ìš”ì•½
                lines.append("  ë§¤ë§¤ì‹ í˜¸:")
                signals_list = all_signals.get(code, [])
                if signals_list:
                    for s in signals_list:
                        lines.append(f"    {s['time']} [{s['types']}]")
                else:
                    lines.append("    ì—†ìŒ")
                # ì²´ê²° ì‹œë®¬ë ˆì´ì…˜ ìš”ì•½ (ë§¤ìˆ˜/ë§¤ë„/%)
                lines.append("  ì²´ê²° ì‹œë®¬ë ˆì´ì…˜:")
                trades_list = all_trades.get(code, [])
                if trades_list:
                    for tr in trades_list:
                        bt = tr.get('buy_time', '')
                        btype = tr.get('buy_type', '')
                        bp = tr.get('buy_price', 0.0)
                        st = tr.get('sell_time', '')
                        srsn = tr.get('sell_reason', '')
                        sp = tr.get('sell_price', 0.0)
                        pr = float(tr.get('profit_rate', 0.0))
                        lines.append(f"    {bt} ë§¤ìˆ˜[{btype}] @{bp:,.0f} â†’ {st} ë§¤ë„[{srsn}] @{sp:,.0f} ({pr:+.2f}%)")
                else:
                    lines.append("    ì—†ìŒ")
                lines.append("")

            content = "\n".join(lines).rstrip() + "\n"
            with open(args.txt_path, "w", encoding="utf-8-sig") as f:
                f.write(content)
            print(f"\nğŸ“„ TXT ì €ì¥ ì™„ë£Œ: {args.txt_path}")
        except Exception as e:
            print(f"\nâŒ TXT ì €ì¥ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    main()


