#!/usr/bin/env python3
"""
ë™ì  ì†ìµë¹„ ML ëª¨ë¸ë¡œ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ í•„í„°ë§

ê¸°ì¡´ apply_ml_filter.pyì™€ ë™ì¼í•˜ì§€ë§Œ ml_model_dynamic_pl.pkl ì‚¬ìš©
"""

import sys
sys.stdout.reconfigure(encoding='utf-8')

import pickle
import re
import json
import sqlite3
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import pandas as pd


# ìƒˆ ML ëª¨ë¸ ì‚¬ìš©
ML_MODEL_PATH = "ml_model_dynamic_pl.pkl"
DEFAULT_THRESHOLD = 0.5


def load_stock_names() -> Dict[str, str]:
    """DBì—ì„œ ì¢…ëª© ì½”ë“œ-ì¢…ëª©ëª… ë§¤í•‘ ë¡œë“œ"""
    try:
        conn = sqlite3.connect('data/robotrader.db')
        cursor = conn.cursor()
        cursor.execute("SELECT DISTINCT stock_code, stock_name FROM candidate_stocks WHERE stock_name IS NOT NULL")
        stock_map = {code: name for code, name in cursor.fetchall()}
        conn.close()
        return stock_map
    except Exception as e:
        print(f"[ê²½ê³ ] ì¢…ëª©ëª… ë¡œë“œ ì‹¤íŒ¨: {e}")
        return {}


def load_ml_model(model_path: str = ML_MODEL_PATH):
    """ML ëª¨ë¸ ë¡œë“œ"""
    try:
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)

        model = model_data['model']
        feature_names = model_data['feature_names']

        print(f"[ML ëª¨ë¸] {model_path} ë¡œë“œ ì™„ë£Œ ({len(feature_names)}ê°œ íŠ¹ì„±)")
        return model, feature_names

    except Exception as e:
        print(f"[ì˜¤ë¥˜] ML ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None, None


def parse_signal_from_log_line(line: str) -> Dict:
    """ë¡œê·¸ ë¼ì¸ì—ì„œ ì‹ í˜¸ ì •ë³´ íŒŒì‹±"""
    pattern = r'[ğŸ”´ğŸŸ¢]\s+(\d{6})(?:\([^)]+\))?\s+(\d{2}):(\d{2})\s+ë§¤ìˆ˜\s+â†’\s+([-+]\d+\.\d+)%'
    match = re.search(pattern, line)

    if not match:
        return None

    stock_code = match.group(1)
    hour = int(match.group(2))
    minute = int(match.group(3))
    profit_rate = float(match.group(4))

    return {
        'stock_code': stock_code,
        'hour': hour,
        'minute': minute,
        'time': f"{hour:02d}:{minute:02d}",
        'profit_rate': profit_rate,
        'is_win': profit_rate > 0
    }


def load_pattern_data_for_date(date_str: str) -> Dict[str, Dict]:
    """íŠ¹ì • ë‚ ì§œì˜ íŒ¨í„´ ë°ì´í„° ë¡œë“œ"""
    pattern_log_file = Path('pattern_data_log') / f'pattern_data_{date_str}.jsonl'

    if not pattern_log_file.exists():
        print(f"   [ê²½ê³ ] íŒ¨í„´ ë¡œê·¸ ì—†ìŒ: {pattern_log_file}")
        return {}

    patterns = {}
    try:
        encodings = ['utf-8', 'cp949', 'utf-8-sig']
        for encoding in encodings:
            try:
                with open(pattern_log_file, 'r', encoding=encoding) as f:
                    for line in f:
                        if line.strip():
                            try:
                                pattern = json.loads(line)
                                pattern_id = pattern.get('pattern_id', '')
                                if pattern_id:
                                    patterns[pattern_id] = pattern
                            except json.JSONDecodeError:
                                continue
                break
            except UnicodeDecodeError:
                continue
    except Exception as e:
        print(f"   [ê²½ê³ ] íŒ¨í„´ ë¡œê·¸ ì½ê¸° ì‹¤íŒ¨: {e}")

    return patterns


def extract_features_from_pattern(pattern: Dict, feature_names: List[str]) -> Optional[pd.Series]:
    """íŒ¨í„´ ë°ì´í„°ì—ì„œ ML í”¼ì²˜ ì¶”ì¶œ"""
    try:
        pattern_stages = pattern.get('pattern_stages', {})
        signal_info = pattern.get('signal_info', {})

        def safe_float(value, default=0.0):
            if value is None:
                return default
            if isinstance(value, (int, float)):
                return float(value)
            if isinstance(value, str):
                return float(value.replace('%', '').replace(',', ''))
            return default

        # 1ë‹¨ê³„: ìƒìŠ¹êµ¬ê°„
        uptrend = pattern_stages.get('1_uptrend', {})
        uptrend_candles = uptrend.get('candle_count', 0)
        uptrend_gain = safe_float(uptrend.get('price_gain', 0))
        uptrend_max_volume = safe_float(uptrend.get('max_volume', 0))
        uptrend_avg_volume = safe_float(uptrend.get('volume_avg', 0))

        # 2ë‹¨ê³„: í•˜ë½êµ¬ê°„
        decline = pattern_stages.get('2_decline', {})
        decline_candles = decline.get('candle_count', 0)
        decline_pct = safe_float(decline.get('decline_pct', 0))
        decline_avg_volume = safe_float(decline.get('avg_volume', 0))

        # 3ë‹¨ê³„: ì§€ì§€êµ¬ê°„
        support = pattern_stages.get('3_support', {})
        support_candles = support.get('candle_count', 0)
        support_avg_volume = safe_float(support.get('avg_volume', 0))
        support_volatility = safe_float(support.get('price_volatility', 0))

        # 4ë‹¨ê³„: ëŒíŒŒì–‘ë´‰
        breakout = pattern_stages.get('4_breakout', {})
        breakout_candle = breakout.get('candle', {})
        breakout_volume = safe_float(breakout_candle.get('volume', 0))
        breakout_close = safe_float(breakout_candle.get('close', 0))

        # ê±°ë˜ëŸ‰ ë¹„ìœ¨ ê³„ì‚°
        support_volume_ratio = support_avg_volume / uptrend_max_volume if uptrend_max_volume > 0 else 0
        decline_volume_ratio = decline_avg_volume / uptrend_avg_volume if uptrend_avg_volume > 0 else 0

        # íŒ¨í„´ ë¶„ë¥˜
        if support_volume_ratio < 0.15:
            support_volume_class = 0  # very_low
        elif support_volume_ratio < 0.25:
            support_volume_class = 1  # low
        elif support_volume_ratio < 0.50:
            support_volume_class = 2  # normal
        else:
            support_volume_class = 3  # high

        if decline_volume_ratio < 0.3:
            decline_volume_class = 0  # strong_decrease
        elif decline_volume_ratio < 0.6:
            decline_volume_class = 1  # normal_decrease
        else:
            decline_volume_class = 2  # weak_decrease

        # ì‹œê°„ ì •ë³´
        signal_time = pattern.get('signal_time', '')
        try:
            dt = datetime.fromisoformat(signal_time)
            hour = dt.hour
            minute = dt.minute
            time_in_minutes = hour * 60 + minute
            is_morning = 1 if hour < 12 else 0
        except:
            hour = minute = time_in_minutes = is_morning = 0

        # í”¼ì²˜ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        features_dict = {
            'uptrend_candles': uptrend_candles,
            'uptrend_gain': uptrend_gain,
            'uptrend_max_volume': uptrend_max_volume,
            'uptrend_avg_volume': uptrend_avg_volume,
            'decline_candles': decline_candles,
            'decline_pct': decline_pct,
            'decline_avg_volume': decline_avg_volume,
            'support_candles': support_candles,
            'support_avg_volume': support_avg_volume,
            'support_volatility': support_volatility,
            'breakout_volume': breakout_volume,
            'breakout_close': breakout_close,
            'support_volume_ratio': support_volume_ratio,
            'decline_volume_ratio': decline_volume_ratio,
            'support_volume_class': support_volume_class,
            'decline_volume_class': decline_volume_class,
            'confidence': signal_info.get('confidence', 0),
            'hour': hour,
            'minute': minute,
            'time_in_minutes': time_in_minutes,
            'is_morning': is_morning
        }

        # feature_names ìˆœì„œëŒ€ë¡œ ê°’ ì¶”ì¶œ
        feature_values = [features_dict.get(name, 0) for name in feature_names]
        return pd.Series(feature_values, index=feature_names)

    except Exception as e:
        print(f"   [ê²½ê³ ] í”¼ì²˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        return None


def apply_ml_filter_to_file(input_file: str, output_file: str, threshold: float = DEFAULT_THRESHOLD):
    """ML í•„í„° ì ìš©"""
    print(f"\n[ML í•„í„°] ì…ë ¥: {input_file}")
    print(f"[ML í•„í„°] ì¶œë ¥: {output_file}")
    print(f"[ML í•„í„°] ì„ê³„ê°’: {threshold:.1%}")

    # ML ëª¨ë¸ ë¡œë“œ
    model, feature_names = load_ml_model()
    if model is None:
        print("[ì˜¤ë¥˜] ML ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    # ì¢…ëª©ëª… ë¡œë“œ
    stock_names = load_stock_names()

    # ì…ë ¥ íŒŒì¼ ì½ê¸°
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            lines = f.readlines()
    except Exception as e:
        print(f"[ì˜¤ë¥˜] íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        return False

    # ë‚ ì§œ ì¶”ì¶œ
    date_match = re.search(r'(\d{8})', input_file)
    if not date_match:
        print("[ì˜¤ë¥˜] íŒŒì¼ëª…ì—ì„œ ë‚ ì§œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    trade_date = date_match.group(1)

    # íŒ¨í„´ ë°ì´í„° ë¡œë“œ
    patterns = load_pattern_data_for_date(trade_date)
    print(f"[íŒ¨í„´ ë¡œê·¸] {len(patterns)}ê°œ íŒ¨í„´ ë¡œë“œë¨")

    # í•„í„°ë§
    total_signals = 0
    passed_signals = 0
    blocked_signals = 0
    output_lines = []
    blocked_details = []  # ğŸ†• ì°¨ë‹¨ëœ ì‹ í˜¸ ìƒì„¸ ì •ë³´

    for line in lines:
        signal = parse_signal_from_log_line(line)

        if signal:
            total_signals += 1

            # íŒ¨í„´ ë§¤ì¹­
            pattern_id = f"{signal['stock_code']}_{trade_date}_{signal['hour']:02d}{signal['minute']:02d}00"
            pattern = patterns.get(pattern_id)

            if pattern:
                # ML ì˜ˆì¸¡
                features = extract_features_from_pattern(pattern, feature_names)
                if features is not None:
                    ml_prob = model.predict(features.values.reshape(1, -1), num_iteration=model.best_iteration)[0]

                    if ml_prob >= threshold:
                        passed_signals += 1
                        output_lines.append(line)
                    else:
                        blocked_signals += 1
                        # ğŸ†• ì°¨ë‹¨ëœ ì‹ í˜¸ ì •ë³´ ìˆ˜ì§‘
                        stock_name = stock_names.get(signal['stock_code'], '???')
                        blocked_details.append({
                            'stock_code': signal['stock_code'],
                            'stock_name': stock_name,
                            'time': signal['time'],
                            'profit_rate': signal['profit_rate'],
                            'ml_prob': ml_prob,
                            'is_win': signal['is_win']
                        })
                else:
                    # í”¼ì²˜ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ í†µê³¼
                    passed_signals += 1
                    output_lines.append(line)
            else:
                # íŒ¨í„´ ì—†ìœ¼ë©´ í†µê³¼
                passed_signals += 1
                output_lines.append(line)
        else:
            # ì‹ í˜¸ê°€ ì•„ë‹Œ ë¼ì¸ì€ ê·¸ëŒ€ë¡œ ì¶œë ¥
            output_lines.append(line)

    # ğŸ†• ì°¨ë‹¨ëœ ì‹ í˜¸ ì„¹ì…˜ ì¶”ê°€
    if blocked_details:
        output_lines.append("\n")
        output_lines.append("=" * 70 + "\n")
        output_lines.append("ğŸš« ML í•„í„°ì— ì˜í•´ ì œì™¸ëœ ì‹ í˜¸\n")
        output_lines.append("=" * 70 + "\n")
        output_lines.append(f"ì´ {len(blocked_details)}ê±´ (ML ìŠ¹ë¥  ì„ê³„ê°’: {threshold:.1%} ë¯¸ë§Œ)\n")
        output_lines.append("\n")

        # ì°¨ë‹¨ëœ ì‹ í˜¸ë¥¼ ê²°ê³¼ë³„ë¡œ ë¶„ë¥˜
        blocked_wins = [d for d in blocked_details if d['is_win']]
        blocked_losses = [d for d in blocked_details if not d['is_win']]

        if blocked_wins:
            output_lines.append(f"âœ… ì‹¤ì œë¡œëŠ” ìˆ˜ìµì´ ë‚¬ì§€ë§Œ ì œì™¸ëœ ì‹ í˜¸: {len(blocked_wins)}ê±´\n")
            for detail in blocked_wins:
                output_lines.append(f"   ğŸŸ¢ {detail['stock_code']}({detail['stock_name']}) {detail['time']} "
                                  f"â†’ +{detail['profit_rate']:.2f}% (ML ìŠ¹ë¥ : {detail['ml_prob']:.1%})\n")
            output_lines.append("\n")

        if blocked_losses:
            output_lines.append(f"âŒ ì†ì‹¤ì´ ë‚¬ê³  ì •í™•íˆ ì œì™¸ëœ ì‹ í˜¸: {len(blocked_losses)}ê±´\n")
            for detail in blocked_losses:
                output_lines.append(f"   ğŸ”´ {detail['stock_code']}({detail['stock_name']}) {detail['time']} "
                                  f"â†’ {detail['profit_rate']:+.2f}% (ML ìŠ¹ë¥ : {detail['ml_prob']:.1%})\n")

        output_lines.append("\n")

    # ê²°ê³¼ ì €ì¥
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(output_lines)
    except Exception as e:
        print(f"[ì˜¤ë¥˜] íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}")
        return False

    # í†µê³„ ì¶œë ¥
    print(f"\n[í•„í„°ë§ ê²°ê³¼]")
    print(f"  ì´ ì‹ í˜¸: {total_signals}ê°œ")
    if total_signals > 0:
        print(f"  í†µê³¼: {passed_signals}ê°œ ({passed_signals/total_signals*100:.1f}%)")
        print(f"  ì°¨ë‹¨: {blocked_signals}ê°œ ({blocked_signals/total_signals*100:.1f}%)")
    else:
        print(f"  í†µê³¼: {passed_signals}ê°œ")
        print(f"  ì°¨ë‹¨: {blocked_signals}ê°œ")

    return True


def main():
    parser = argparse.ArgumentParser(description='ë™ì  ì†ìµë¹„ ML ëª¨ë¸ë¡œ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ í•„í„°ë§')
    parser.add_argument('input_file', help='ì…ë ¥ íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--output', '-o', help='ì¶œë ¥ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸: ì…ë ¥_ml_filtered.txt)')
    parser.add_argument('--threshold', '-t', type=float, default=DEFAULT_THRESHOLD, help=f'ML ì„ê³„ê°’ (ê¸°ë³¸: {DEFAULT_THRESHOLD})')

    args = parser.parse_args()

    # ì¶œë ¥ íŒŒì¼ëª… ì„¤ì •
    if args.output:
        output_file = args.output
    else:
        input_path = Path(args.input_file)
        output_file = str(input_path.parent / f"{input_path.stem}_ml_filtered{input_path.suffix}")

    # í•„í„° ì ìš©
    success = apply_ml_filter_to_file(args.input_file, output_file, args.threshold)

    if success:
        print(f"\n[ì™„ë£Œ] {output_file}")
        sys.exit(0)
    else:
        print(f"\n[ì‹¤íŒ¨]")
        sys.exit(1)


if __name__ == "__main__":
    main()
