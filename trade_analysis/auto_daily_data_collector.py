"""
ìë™ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ê¸°
ë¶„ì„ì— í•„ìš”í•œ ì¢…ëª©ì˜ ì¼ë´‰ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ ìˆ˜ì§‘
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Set
from datetime import datetime, timedelta
import logging
from pathlib import Path
import pickle
import json
import time
import re

from api.kis_market_api import get_inquire_daily_itemchartprice
from api.kis_auth import auth
from utils.logger import setup_logger
from utils.korean_time import now_kst

class AutoDailyDataCollector:
    """ìë™ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, logger=None):
        self.logger = logger or setup_logger(__name__)
        self.cache_dir = Path("cache/daily_data")
        self.cache_dir.mkdir(exist_ok=True)
        self.collected_count = 0
        self.failed_count = 0
        self.is_authenticated = False
        
    def collect_missing_daily_data(self, stock_codes: List[str], start_date: str = None, end_date: str = None) -> Dict[str, bool]:
        """ëˆ„ë½ëœ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # KIS ì¸ì¦ í™•ì¸ ë° ì‹¤í–‰
            if not self._ensure_authenticated():
                self.logger.error("âŒ KIS ì¸ì¦ ì‹¤íŒ¨ë¡œ ë°ì´í„° ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return {}
            
            if start_date is None:
                start_date = "20240601"  # 6ì›” 1ì¼ë¶€í„°
            if end_date is None:
                end_date = now_kst().strftime("%Y%m%d")  # ì˜¤ëŠ˜ê¹Œì§€
            
            self.logger.info(f"ğŸ” ëˆ„ë½ëœ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")
            self.logger.info(f"ğŸ“Š ëŒ€ìƒ ì¢…ëª©: {len(stock_codes)}ê°œ")
            
            # 1. ëˆ„ë½ëœ ì¢…ëª© í™•ì¸
            missing_stocks = self._find_missing_stocks(stock_codes, start_date, end_date)
            self.logger.info(f"ğŸ“‹ ëˆ„ë½ëœ ì¢…ëª©: {len(missing_stocks)}ê°œ")
            
            if not missing_stocks:
                self.logger.info("âœ… ëª¨ë“  ì¢…ëª©ì˜ ì¼ë´‰ ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤.")
                return {}
            
            # 2. ëˆ„ë½ëœ ì¢…ëª©ì˜ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
            collection_results = {}
            for i, stock_code in enumerate(missing_stocks, 1):
                self.logger.info(f"ğŸ“ˆ [{i}/{len(missing_stocks)}] {stock_code} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                
                try:
                    success = self._collect_single_stock_daily_data(stock_code, start_date, end_date)
                    collection_results[stock_code] = success
                    
                    if success:
                        self.collected_count += 1
                        self.logger.info(f"âœ… {stock_code} ìˆ˜ì§‘ ì™„ë£Œ")
                    else:
                        self.failed_count += 1
                        self.logger.warning(f"âš ï¸ {stock_code} ìˆ˜ì§‘ ì‹¤íŒ¨")
                    
                    # API í˜¸ì¶œ ì œí•œ ê³ ë ¤
                    time.sleep(0.1)
                    
                except Exception as e:
                    self.failed_count += 1
                    collection_results[stock_code] = False
                    self.logger.error(f"âŒ {stock_code} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                    continue
            
            # 3. ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½
            self._log_collection_summary(collection_results)
            
            return collection_results
            
        except Exception as e:
            self.logger.error(f"ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _find_missing_stocks(self, stock_codes: List[str], start_date: str, end_date: str) -> List[str]:
        """ëˆ„ë½ëœ ì¢…ëª© ì°¾ê¸°"""
        missing_stocks = []
        
        for stock_code in stock_codes:
            try:
                # ê¸°ì¡´ ì¼ë´‰ ë°ì´í„° í™•ì¸
                daily_file = self.cache_dir / f"{stock_code}_daily.pkl"
                
                if not daily_file.exists():
                    missing_stocks.append(stock_code)
                    continue
                
                # ë°ì´í„° ìœ íš¨ì„± í™•ì¸
                with open(daily_file, 'rb') as f:
                    data = pickle.load(f)
                
                if data is None or data.empty:
                    missing_stocks.append(stock_code)
                    continue
                
                # ë‚ ì§œ ë²”ìœ„ í™•ì¸
                if 'stck_bsop_date' in data.columns:
                    data['date'] = pd.to_datetime(data['stck_bsop_date'])
                    min_date = data['date'].min()
                    max_date = data['date'].max()
                    
                    start_dt = pd.to_datetime(start_date)
                    end_dt = pd.to_datetime(end_date)
                    
                    # í•„ìš”í•œ ë‚ ì§œ ë²”ìœ„ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    if min_date > start_dt or max_date < end_dt:
                        missing_stocks.append(stock_code)
                        self.logger.debug(f"ğŸ“… {stock_code} ë‚ ì§œ ë²”ìœ„ ë¶€ì¡±: {min_date.date()} ~ {max_date.date()}")
                
            except Exception as e:
                self.logger.debug(f"ğŸ“‹ {stock_code} ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
                missing_stocks.append(stock_code)
        
        return missing_stocks
    
    def _collect_single_stock_daily_data(self, stock_code: str, start_date: str, end_date: str) -> bool:
        """ë‹¨ì¼ ì¢…ëª© ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            # API í˜¸ì¶œ (output_dv="2"ë¡œ ì„¤ì •í•˜ì—¬ ì „ì²´ ë°ì´í„° ì¡°íšŒ)
            data = get_inquire_daily_itemchartprice(
                itm_no=stock_code,
                period_code="D",
                adj_prc="1",
                inqr_strt_dt=start_date,
                inqr_end_dt=end_date,
                output_dv="2"  # ì „ì²´ ë°ì´í„° ì¡°íšŒ
            )
            
            if data is None or data.empty:
                self.logger.debug(f"ğŸ“Š {stock_code} API ì‘ë‹µ ì—†ìŒ")
                return False
            
            # ë°ì´í„° ì •ë¦¬
            cleaned_data = self._clean_daily_data(data)
            
            if cleaned_data is None or cleaned_data.empty:
                self.logger.debug(f"ğŸ§¹ {stock_code} ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨")
                return False
            
            # ë°ì´í„° ì €ì¥
            daily_file = self.cache_dir / f"{stock_code}_daily.pkl"
            with open(daily_file, 'wb') as f:
                pickle.dump(cleaned_data, f)
            
            self.logger.debug(f"ğŸ’¾ {stock_code} ë°ì´í„° ì €ì¥ ì™„ë£Œ: {len(cleaned_data)}ê±´")
            return True
            
        except Exception as e:
            self.logger.debug(f"ğŸ“ˆ {stock_code} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return False
    
    def _clean_daily_data(self, data: pd.DataFrame) -> Optional[pd.DataFrame]:
        """ì¼ë´‰ ë°ì´í„° ì •ë¦¬"""
        try:
            if data is None or data.empty:
                return None
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = ['stck_bsop_date', 'stck_clpr', 'stck_oprc', 'stck_hgpr', 'stck_lwpr', 'acml_vol']
            missing_columns = [col for col in required_columns if col not in data.columns]
            
            if missing_columns:
                self.logger.debug(f"ğŸ“‹ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
                return None
            
            # ë°ì´í„° íƒ€ì… ë³€í™˜
            cleaned_data = data.copy()
            
            # ë‚ ì§œ ë³€í™˜
            cleaned_data['date'] = pd.to_datetime(cleaned_data['stck_bsop_date'])
            
            # ê°€ê²© ë°ì´í„° ë³€í™˜
            price_columns = ['stck_clpr', 'stck_oprc', 'stck_hgpr', 'stck_lwpr']
            for col in price_columns:
                cleaned_data[col] = pd.to_numeric(cleaned_data[col], errors='coerce')
            
            # ê±°ë˜ëŸ‰ ë³€í™˜
            cleaned_data['acml_vol'] = pd.to_numeric(cleaned_data['acml_vol'], errors='coerce')
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬
            cleaned_data = cleaned_data.rename(columns={
                'stck_clpr': 'close',
                'stck_oprc': 'open',
                'stck_hgpr': 'high',
                'stck_lwpr': 'low',
                'acml_vol': 'volume'
            })
            
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„° ì œê±°
            cleaned_data = cleaned_data.dropna(subset=['date', 'close', 'open', 'high', 'low', 'volume'])
            
            # ë‚ ì§œìˆœ ì •ë ¬
            cleaned_data = cleaned_data.sort_values('date').reset_index(drop=True)
            
            # ì¤‘ë³µ ì œê±°
            cleaned_data = cleaned_data.drop_duplicates(subset=['date']).reset_index(drop=True)
            
            return cleaned_data
            
        except Exception as e:
            self.logger.debug(f"ğŸ§¹ ë°ì´í„° ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return None
    
    def _log_collection_summary(self, collection_results: Dict[str, bool]):
        """ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ë¡œê·¸"""
        total_stocks = len(collection_results)
        successful_stocks = sum(collection_results.values())
        failed_stocks = total_stocks - successful_stocks
        
        self.logger.info("\n" + "="*60)
        self.logger.info("ğŸ“Š ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½")
        self.logger.info("="*60)
        self.logger.info(f"ì´ ëŒ€ìƒ ì¢…ëª©: {total_stocks}ê°œ")
        self.logger.info(f"ìˆ˜ì§‘ ì„±ê³µ: {successful_stocks}ê°œ")
        self.logger.info(f"ìˆ˜ì§‘ ì‹¤íŒ¨: {failed_stocks}ê°œ")
        self.logger.info(f"ì„±ê³µë¥ : {successful_stocks/total_stocks*100:.1f}%")
        
        if failed_stocks > 0:
            self.logger.info("\nâŒ ìˆ˜ì§‘ ì‹¤íŒ¨í•œ ì¢…ëª©:")
            for stock_code, success in collection_results.items():
                if not success:
                    self.logger.info(f"  - {stock_code}")
        
        self.logger.info("="*60)
    
    def _log_quality_report(self, quality_report: Dict[str, Dict]):
        """í’ˆì§ˆ ë³´ê³ ì„œ ë¡œê·¸ ì¶œë ¥"""
        try:
            total_stocks = len(quality_report)
            ok_stocks = sum(1 for report in quality_report.values() if report['status'] == 'ok')
            missing_stocks = sum(1 for report in quality_report.values() if report['status'] == 'missing')
            error_stocks = sum(1 for report in quality_report.values() if report['status'] == 'error')
            
            self.logger.info("\n" + "="*60)
            self.logger.info("ğŸ“Š ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ê²°ê³¼")
            self.logger.info("="*60)
            self.logger.info(f"ì´ ì¢…ëª©: {total_stocks}ê°œ")
            self.logger.info(f"ì •ìƒ: {ok_stocks}ê°œ")
            self.logger.info(f"ëˆ„ë½: {missing_stocks}ê°œ")
            self.logger.info(f"ì˜¤ë¥˜: {error_stocks}ê°œ")
            
            if ok_stocks > 0:
                avg_quality = sum(report['quality_score'] for report in quality_report.values() 
                                if report['status'] == 'ok') / ok_stocks
                self.logger.info(f"í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.2f}")
            
            self.logger.info("="*60)
            
        except Exception as e:
            self.logger.error(f"í’ˆì§ˆ ë³´ê³ ì„œ ì¶œë ¥ ì‹¤íŒ¨: {e}")
    
    def _ensure_authenticated(self) -> bool:
        """KIS ì¸ì¦ ìƒíƒœ í™•ì¸ ë° ì¸ì¦ ì‹¤í–‰"""
        try:
            if self.is_authenticated:
                return True
            
            self.logger.info("ğŸ” KIS API ì¸ì¦ ì‹œì‘...")
            
            # KIS ì¸ì¦ ì‹¤í–‰
            if auth():
                self.is_authenticated = True
                self.logger.info("âœ… KIS API ì¸ì¦ ì„±ê³µ")
                return True
            else:
                self.logger.error("âŒ KIS API ì¸ì¦ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ KIS ì¸ì¦ ì˜¤ë¥˜: {e}")
            return False
    
    def collect_from_trade_logs(self, log_dir: str = "signal_replay_log") -> Dict[str, bool]:
        """ê±°ë˜ ë¡œê·¸ì—ì„œ ì¢…ëª© ì¶”ì¶œí•˜ì—¬ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘"""
        try:
            self.logger.info("ğŸ“‹ ê±°ë˜ ë¡œê·¸ì—ì„œ ì¢…ëª© ì¶”ì¶œ ì¤‘...")
            
            # 1. ê±°ë˜ ë¡œê·¸ì—ì„œ ì¢…ëª© ì¶”ì¶œ
            stock_codes = self._extract_stocks_from_logs(log_dir)
            self.logger.info(f"ğŸ“Š ì¶”ì¶œëœ ì¢…ëª©: {len(stock_codes)}ê°œ")
            
            if not stock_codes:
                self.logger.warning("ê±°ë˜ ë¡œê·¸ì—ì„œ ì¢…ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return {}
            
            # 2. ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
            collection_results = self.collect_missing_daily_data(stock_codes)
            
            return collection_results
            
        except Exception as e:
            self.logger.error(f"ê±°ë˜ ë¡œê·¸ ê¸°ë°˜ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return {}
    
    def _extract_stocks_from_logs(self, log_dir: str) -> Set[str]:
        """ê±°ë˜ ë¡œê·¸ì—ì„œ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ"""
        stock_codes = set()
        log_path = Path(log_dir)
        
        if not log_path.exists():
            self.logger.warning(f"ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {log_dir}")
            return stock_codes
        
        for log_file in log_path.glob("*.txt"):
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ì¢…ëª©ì½”ë“œ ì¶”ì¶œ (=== 6ìë¦¬ìˆ«ì - íŒ¨í„´)
                matches = re.findall(r'=== (\d{6}) -', content)
                stock_codes.update(matches)
                
            except Exception as e:
                self.logger.debug(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ {log_file.name}: {e}")
                continue
        
        return stock_codes
    
    def verify_data_quality(self, stock_codes: List[str]) -> Dict[str, Dict]:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        try:
            self.logger.info("ğŸ” ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œì‘...")
            
            quality_report = {}
            
            for stock_code in stock_codes:
                try:
                    daily_file = self.cache_dir / f"{stock_code}_daily.pkl"
                    
                    if not daily_file.exists():
                        quality_report[stock_code] = {
                            'status': 'missing',
                            'records': 0,
                            'date_range': None,
                            'quality_score': 0.0
                        }
                        continue
                    
                    with open(daily_file, 'rb') as f:
                        data = pickle.load(f)
                    
                    if data is None or data.empty:
                        quality_report[stock_code] = {
                            'status': 'empty',
                            'records': 0,
                            'date_range': None,
                            'quality_score': 0.0
                        }
                        continue
                    
                    # ë°ì´í„° í’ˆì§ˆ í‰ê°€
                    records = len(data)
                    date_range = None
                    quality_score = 0.0
                    
                    if 'date' in data.columns:
                        dates = pd.to_datetime(data['date'])
                        date_range = {
                            'start': dates.min().strftime('%Y-%m-%d'),
                            'end': dates.max().strftime('%Y-%m-%d'),
                            'days': len(dates.unique())
                        }
                        
                        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
                        quality_score = min(1.0, records / 100)  # 100ê±´ ì´ìƒì´ë©´ 1.0
                    
                    quality_report[stock_code] = {
                        'status': 'ok',
                        'records': records,
                        'date_range': date_range,
                        'quality_score': quality_score
                    }
                    
                except Exception as e:
                    quality_report[stock_code] = {
                        'status': 'error',
                        'records': 0,
                        'date_range': None,
                        'quality_score': 0.0,
                        'error': str(e)
                    }
            
            # í’ˆì§ˆ ë³´ê³ ì„œ ì¶œë ¥
            self._log_quality_report(quality_report)
            
            return quality_report
            
        except Exception as e:
            self.logger.error(f"ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return {}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger = setup_logger(__name__)
    
    # ìë™ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ê¸° ì‹¤í–‰
    collector = AutoDailyDataCollector(logger)
    
    # 1. ê±°ë˜ ë¡œê·¸ì—ì„œ ì¢…ëª© ì¶”ì¶œí•˜ì—¬ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
    logger.info("ğŸš€ ìë™ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    
    collection_results = collector.collect_from_trade_logs()
    
    if collection_results:
        # 2. ìˆ˜ì§‘ëœ ì¢…ëª©ë“¤ì˜ ë°ì´í„° í’ˆì§ˆ ê²€ì¦
        collected_stocks = [stock for stock, success in collection_results.items() if success]
        
        if collected_stocks:
            quality_report = collector.verify_data_quality(collected_stocks)
            
            # 3. í’ˆì§ˆì´ ì¢‹ì€ ë°ì´í„°ë§Œ í•„í„°ë§
            good_quality_stocks = [
                stock for stock, report in quality_report.items() 
                if report['status'] == 'ok' and report['quality_score'] > 0.5
            ]
            
            logger.info(f"âœ… í’ˆì§ˆì´ ì¢‹ì€ ë°ì´í„°: {len(good_quality_stocks)}ê°œ ì¢…ëª©")
            
            # 4. ë¶„ì„ ê°€ëŠ¥í•œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì €ì¥
            with open('analysis_ready_stocks.json', 'w', encoding='utf-8') as f:
                json.dump(good_quality_stocks, f, ensure_ascii=False, indent=2)
            
            logger.info("ğŸ’¾ ë¶„ì„ ê°€ëŠ¥í•œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ì €ì¥ ì™„ë£Œ: analysis_ready_stocks.json")
    
    logger.info("ğŸ ìë™ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")


if __name__ == "__main__":
    main()
