#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹œ ì‹œìŠ¤í…œ
- ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹œ ê´€ë¦¬
- ë¶„ë´‰ ë°ì´í„°ì™€ ì¼ë´‰ ë°ì´í„° ê²°í•©
- í•™ìŠµìš© íŠ¹ì„± ì¶”ì¶œ
"""

import os
import sys
import sqlite3
import pickle
import pandas as pd
import numpy as np
import re
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
import logging
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from api.kis_market_api import get_inquire_daily_itemchartprice
from api.kis_auth import auth
from utils.korean_time import now_kst
from utils.logger import setup_logger
from .ml_feature_engineer import MLFeatureEngineer

logger = setup_logger(__name__)

class MLDataCollector:
    """ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, 
                 db_path: str = "data/robotrader.db",
                 minute_cache_dir: str = "cache/minute_data",
                 daily_cache_dir: str = "cache/daily_data",
                 signal_log_dir: str = "signal_replay_log"):
        self.db_path = db_path
        self.minute_cache_dir = Path(minute_cache_dir)
        self.daily_cache_dir = Path(daily_cache_dir)
        self.signal_log_dir = Path(signal_log_dir)
        
        # íŠ¹ì„± ì¶”ì¶œ ì—”ì§„ ì´ˆê¸°í™”
        self.feature_engineer = MLFeatureEngineer()
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.daily_cache_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ML ë°ì´í„° ìˆ˜ì§‘ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info(f"   - DB: {db_path}")
        logger.info(f"   - ë¶„ë´‰ ìºì‹œ: {self.minute_cache_dir}")
        logger.info(f"   - ì¼ë´‰ ìºì‹œ: {self.daily_cache_dir}")
        logger.info(f"   - ì‹ í˜¸ ë¡œê·¸: {self.signal_log_dir}")
    
    def get_candidate_stocks_by_date(self, start_date: str, end_date: str) -> Dict[str, List[Dict]]:
        """íŠ¹ì • ê¸°ê°„ì˜ í›„ë³´ ì¢…ëª© ì¡°íšŒ (ì‹ í˜¸ ë¡œê·¸ì—ì„œ ì¶”ì¶œ)"""
        try:
            # ë¨¼ì € ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ ì‹œë„
            if os.path.exists(self.db_path):
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        SELECT stock_code, stock_name, selection_date, selection_reason
                        FROM candidate_stocks 
                        WHERE DATE(selection_date) BETWEEN ? AND ?
                        ORDER BY selection_date, stock_code
                    """, (start_date, end_date))
                    
                    results = cursor.fetchall()
                    
                    if results:
                        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
                        stocks_by_date = {}
                        for row in results:
                            stock_code, stock_name, selection_date, selection_reason = row
                            date_str = selection_date.split(' ')[0]  # ë‚ ì§œ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                            
                            if date_str not in stocks_by_date:
                                stocks_by_date[date_str] = []
                            
                            stocks_by_date[date_str].append({
                                'stock_code': stock_code,
                                'stock_name': stock_name,
                                'selection_date': selection_date,
                                'selection_reason': selection_reason
                            })
                        
                        logger.info(f"{start_date}~{end_date} ê¸°ê°„ í›„ë³´ ì¢…ëª©: {len(results)}ê°œ")
                        return stocks_by_date
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‹ í˜¸ ë¡œê·¸ì—ì„œ ì¶”ì¶œ
            logger.info("ì‹ í˜¸ ë¡œê·¸ì—ì„œ ì¢…ëª© ì •ë³´ ì¶”ì¶œ")
            return self._extract_stocks_from_logs(start_date, end_date)
                
        except Exception as e:
            logger.error(f"í›„ë³´ ì¢…ëª© ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return self._extract_stocks_from_logs(start_date, end_date)
    
    def _extract_stocks_from_logs(self, start_date: str, end_date: str) -> Dict[str, List[Dict]]:
        """ì‹ í˜¸ ë¡œê·¸ì—ì„œ ì¢…ëª© ì •ë³´ ì¶”ì¶œ"""
        stocks_by_date = {}
        
        try:
            for log_file in self.signal_log_dir.glob("signal_*.txt"):
                date_match = re.search(r'(\d{8})', log_file.name)
                if date_match:
                    log_date = date_match.group(1)
                    if start_date <= log_date <= end_date:
                        # ë¡œê·¸ íŒŒì¼ì—ì„œ ì¢…ëª© ì½”ë“œ ì¶”ì¶œ
                        with open(log_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # ì¢…ëª© ì½”ë“œ íŒ¨í„´ ì°¾ê¸° (=== 054540 - 20250905 í˜•íƒœ)
                        stock_matches = re.findall(r'=== (\d{6}) - (\d{8})', content)
                        
                        for stock_code, date_str in stock_matches:
                            if date_str not in stocks_by_date:
                                stocks_by_date[date_str] = []
                            
                            stocks_by_date[date_str].append({
                                'stock_code': stock_code,
                                'stock_name': f'ì¢…ëª©_{stock_code}',  # ì´ë¦„ì€ ì¶”í›„ ì¡°íšŒ
                                'selection_date': f'{date_str} 09:00:00',
                                'selection_reason': 'signal_log_extracted'
                            })
            
            total_stocks = sum(len(stocks) for stocks in stocks_by_date.values())
            logger.info(f"ì‹ í˜¸ ë¡œê·¸ì—ì„œ ì¶”ì¶œí•œ ì¢…ëª©: {total_stocks}ê°œ")
            return stocks_by_date
            
        except Exception as e:
            logger.error(f"ì‹ í˜¸ ë¡œê·¸ì—ì„œ ì¢…ëª© ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    def collect_daily_data(self, stock_code: str, days: int = 60) -> Optional[pd.DataFrame]:
        """ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ë° ìºì‹œ"""
        try:
            # ìºì‹œ íŒŒì¼ ê²½ë¡œ
            cache_file = self.daily_cache_dir / f"{stock_code}_daily.pkl"
            
            # ìºì‹œëœ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if cache_file.exists():
                cache_time = datetime.fromtimestamp(cache_file.stat().st_mtime)
                # ì‹œê°„ëŒ€ ë¬¸ì œ í•´ê²°: naive datetimeì„ KSTë¡œ ë³€í™˜
                if cache_time.tzinfo is None:
                    cache_time = cache_time.replace(tzinfo=None)
                current_time = now_kst().replace(tzinfo=None)
                if (current_time - cache_time).days < 1:  # 1ì¼ ì´ë‚´ ìºì‹œ
                    logger.debug(f"{stock_code} ì¼ë´‰ ë°ì´í„° ìºì‹œ ì‚¬ìš©")
                    with open(cache_file, 'rb') as f:
                        return pickle.load(f)
            
            # KIS API ì¸ì¦ í™•ì¸ ë° ì‹¤í–‰
            logger.info(f"KIS API ì¸ì¦ í™•ì¸")
            auth_result = auth()
            if not auth_result:
                logger.error(f"KIS API ì¸ì¦ ì‹¤íŒ¨")
                return None
            
            # APIë¡œ ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
            logger.info(f"{stock_code} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ({days}ì¼)")
            
            end_date = now_kst().strftime("%Y%m%d")
            start_date = (now_kst() - timedelta(days=days+10)).strftime("%Y%m%d")  # ì—¬ìœ ë¶„ ì¶”ê°€
            
            daily_data = get_inquire_daily_itemchartprice(
                output_dv="2",  # ìƒì„¸ ë°ì´í„°
                div_code="J",   # ì£¼ì‹
                itm_no=stock_code,
                inqr_strt_dt=start_date,
                inqr_end_dt=end_date,
                period_code="D",  # ì¼ë´‰
                adj_prc="1"     # ì›ì£¼ê°€
            )
            
            if daily_data is None or daily_data.empty:
                logger.warning(f"{stock_code} ì¼ë´‰ ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨")
                return None
            
            # ë°ì´í„° ì •ì œ
            daily_data = daily_data.copy()
            daily_data['stck_bsop_date'] = pd.to_datetime(daily_data['stck_bsop_date'])
            daily_data = daily_data.sort_values('stck_bsop_date').reset_index(drop=True)
            
            # ìµœê·¼ daysì¼ë§Œ ì„ íƒ
            if len(daily_data) > days:
                daily_data = daily_data.tail(days)
            
            # ìºì‹œì— ì €ì¥
            with open(cache_file, 'wb') as f:
                pickle.dump(daily_data, f)
            
            logger.info(f"{stock_code} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(daily_data)}ê°œ")
            return daily_data
            
        except Exception as e:
            logger.error(f"{stock_code} ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return None
    
    def load_minute_data(self, stock_code: str, date: str) -> Optional[pd.DataFrame]:
        """ë¶„ë´‰ ë°ì´í„° ë¡œë“œ"""
        try:
            # ë¶„ë´‰ ìºì‹œ íŒŒì¼ ê²½ë¡œ (ê¸°ì¡´ í˜•ì‹ ìœ ì§€)
            minute_file = self.minute_cache_dir / f"{stock_code}_{date}.pkl"
            
            if not minute_file.exists():
                logger.warning(f"ë¶„ë´‰ ë°ì´í„° ì—†ìŒ: {stock_code} {date}")
                return None
            
            with open(minute_file, 'rb') as f:
                minute_data = pickle.load(f)
            
            logger.debug(f"{stock_code} {date} ë¶„ë´‰ ë°ì´í„° ë¡œë“œ: {len(minute_data)}ê°œ")
            return minute_data
            
        except Exception as e:
            logger.error(f"{stock_code} {date} ë¶„ë´‰ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def parse_signal_log(self, log_file: Path) -> List[Dict[str, Any]]:
        """ì‹ í˜¸ ì¬í˜„ ë¡œê·¸ íŒŒì‹±"""
        trades = []
        
        try:
            with open(log_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ìŠ¹íŒ¨ ì •ë³´ ì¶”ì¶œ
            win_loss_match = re.search(r'=== ì´ ìŠ¹íŒ¨: (\d+)ìŠ¹ (\d+)íŒ¨ ===', content)
            if win_loss_match:
                total_wins = int(win_loss_match.group(1))
                total_losses = int(win_loss_match.group(2))
            
            # ì¢…ëª©ë³„ ê±°ë˜ ì •ë³´ ì¶”ì¶œ
            stock_sections = re.split(r'=== (\d{6}) - (\d{8})', content)[1:]  # ì²« ë²ˆì§¸ ë¹ˆ ìš”ì†Œ ì œê±°
            
            for i in range(0, len(stock_sections), 3):  # ë§¤ 3ê°œì”© ì²˜ë¦¬ (stock_code, date, content)
                if i + 2 < len(stock_sections):
                    stock_code = stock_sections[i]
                    date = stock_sections[i + 1]
                    section_content = stock_sections[i + 2]
                    
                    # ìŠ¹íŒ¨ ì •ë³´ ì¶”ì¶œ
                    win_loss_match = re.search(r'ìŠ¹íŒ¨: (\d+)ìŠ¹ (\d+)íŒ¨', section_content)
                    if win_loss_match:
                        wins = int(win_loss_match.group(1))
                        losses = int(win_loss_match.group(2))
                        
                        # ì²´ê²° ì‹œë®¬ë ˆì´ì…˜ ì •ë³´ ì¶”ì¶œ
                        trade_matches = re.findall(
                            r'(\d{2}:\d{2}) ë§¤ìˆ˜\[([^\]]+)\] @([\d,]+) â†’ (\d{2}:\d{2}) ë§¤ë„\[([^\]]+)\] @([\d,]+) \(([+-]?\d+\.?\d*)%\)',
                            section_content
                        )
                        
                        for trade in trade_matches:
                            buy_time, signal_type, buy_price, sell_time, sell_reason, sell_price, profit_pct = trade
                            
                            trades.append({
                                'stock_code': stock_code,
                                'date': date,
                                'buy_time': buy_time,
                                'sell_time': sell_time,
                                'buy_price': float(buy_price.replace(',', '')),
                                'sell_price': float(sell_price.replace(',', '')),
                                'profit_pct': float(profit_pct),
                                'signal_type': signal_type,
                                'sell_reason': sell_reason,
                                'is_win': float(profit_pct) > 0,
                                'wins': wins,
                                'losses': losses
                            })
            
            logger.info(f"{log_file.name} íŒŒì‹± ì™„ë£Œ: {len(trades)}ê°œ ê±°ë˜")
            return trades
            
        except Exception as e:
            logger.error(f"{log_file.name} íŒŒì‹± ì‹¤íŒ¨: {e}")
            return []
    
    def collect_ml_training_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """ë¨¸ì‹ ëŸ¬ë‹ í•™ìŠµìš© ë°ì´í„° ìˆ˜ì§‘"""
        logger.info(f"ML í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")
        
        all_trades = []
        
        # 1. í›„ë³´ ì¢…ëª© ì¡°íšŒ
        stocks_by_date = self.get_candidate_stocks_by_date(start_date, end_date)
        
        # 2. ì‹ í˜¸ ë¡œê·¸ì—ì„œ ê±°ë˜ ì •ë³´ ì¶”ì¶œ
        for log_file in self.signal_log_dir.glob("signal_*.txt"):
            date_match = re.search(r'(\d{8})', log_file.name)
            if date_match:
                log_date = date_match.group(1)
                if start_date <= log_date <= end_date:
                    trades = self.parse_signal_log(log_file)
                    all_trades.extend(trades)
        
        # 3. ê±°ë˜ë³„ íŠ¹ì„± ë°ì´í„° ìˆ˜ì§‘
        training_data = []
        
        for trade in all_trades:
            stock_code = trade['stock_code']
            date = trade['date']
            
            logger.info(f"íŠ¹ì„± ë°ì´í„° ìˆ˜ì§‘: {stock_code} {date}")
            
            # ë¶„ë´‰ ë°ì´í„° ë¡œë“œ
            minute_data = self.load_minute_data(stock_code, date)
            if minute_data is None:
                continue
            
            # ì¼ë´‰ ë°ì´í„° ìˆ˜ì§‘
            daily_data = self.collect_daily_data(stock_code, 60)
            if daily_data is None:
                continue
            
            # íŠ¹ì„± ì¶”ì¶œ
            features = self.feature_engineer.extract_comprehensive_features(minute_data, daily_data, trade)
            if features:
                training_data.append(features)
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        if training_data:
            df = pd.DataFrame(training_data)
            logger.info(f"ML í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}ê°œ ìƒ˜í”Œ")
            return df
        else:
            logger.warning("ìˆ˜ì§‘ëœ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return pd.DataFrame()
    
    def extract_features(self, minute_data: pd.DataFrame, daily_data: pd.DataFrame, trade: Dict) -> Optional[Dict]:
        """íŠ¹ì„± ì¶”ì¶œ"""
        try:
            # ê¸°ë³¸ ê±°ë˜ ì •ë³´
            features = {
                'stock_code': trade['stock_code'],
                'date': trade['date'],
                'buy_time': trade['buy_time'],
                'sell_time': trade['sell_time'],
                'profit_pct': trade['profit_pct'],
                'is_win': trade['is_win'],
                'signal_type': trade['signal_type'],
                'sell_reason': trade['sell_reason']
            }
            
            # ë¶„ë´‰ íŠ¹ì„± ì¶”ì¶œ
            minute_features = self.extract_minute_features(minute_data, trade)
            features.update(minute_features)
            
            # ì¼ë´‰ íŠ¹ì„± ì¶”ì¶œ
            daily_features = self.extract_daily_features(daily_data, trade)
            features.update(daily_features)
            
            return features
            
        except Exception as e:
            logger.error(f"íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨ {trade['stock_code']}: {e}")
            return None
    
    def extract_minute_features(self, minute_data: pd.DataFrame, trade: Dict) -> Dict:
        """ë¶„ë´‰ íŠ¹ì„± ì¶”ì¶œ"""
        features = {}
        
        try:
            # ê¸°ë³¸ í†µê³„
            features['minute_data_count'] = len(minute_data)
            features['avg_volume'] = minute_data['volume'].mean()
            features['max_volume'] = minute_data['volume'].max()
            features['volume_std'] = minute_data['volume'].std()
            
            # ê°€ê²© ë³€ë™ì„±
            features['price_volatility'] = minute_data['close'].std() / minute_data['close'].mean()
            features['price_range'] = (minute_data['high'].max() - minute_data['low'].min()) / minute_data['close'].mean()
            
            # ê±°ë˜ëŸ‰ íŒ¨í„´
            features['volume_trend'] = self.calculate_volume_trend(minute_data)
            features['volume_consistency'] = 1 - (minute_data['volume'].std() / minute_data['volume'].mean())
            
            # ì‹œê°„ëŒ€ë³„ íŠ¹ì„±
            buy_time = trade['buy_time']
            hour = int(buy_time.split(':')[0])
            features['buy_hour'] = hour
            features['is_morning_session'] = 1 if 9 <= hour < 12 else 0
            features['is_afternoon_session'] = 1 if 12 <= hour < 15 else 0
            
            return features
            
        except Exception as e:
            logger.error(f"ë¶„ë´‰ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    def extract_daily_features(self, daily_data: pd.DataFrame, trade: Dict) -> Dict:
        """ì¼ë´‰ íŠ¹ì„± ì¶”ì¶œ"""
        features = {}
        
        try:
            # ì´ë™í‰ê· ì„ 
            daily_data['ma5'] = daily_data['stck_clpr'].rolling(5).mean()
            daily_data['ma20'] = daily_data['stck_clpr'].rolling(20).mean()
            daily_data['ma60'] = daily_data['stck_clpr'].rolling(60).mean()
            
            # í˜„ì¬ê°€ ëŒ€ë¹„ ì´ë™í‰ê·  ìœ„ì¹˜
            current_price = daily_data['stck_clpr'].iloc[-1]
            features['ma5_position'] = (current_price - daily_data['ma5'].iloc[-1]) / daily_data['ma5'].iloc[-1]
            features['ma20_position'] = (current_price - daily_data['ma20'].iloc[-1]) / daily_data['ma20'].iloc[-1]
            features['ma60_position'] = (current_price - daily_data['ma60'].iloc[-1]) / daily_data['ma60'].iloc[-1]
            
            # RSI ê³„ì‚°
            features['rsi_14'] = self.calculate_rsi(daily_data['stck_clpr'], 14)
            
            # ê±°ë˜ëŸ‰ ë¶„ì„
            features['volume_ma20_ratio'] = daily_data['acml_vol'].iloc[-1] / daily_data['acml_vol'].rolling(20).mean().iloc[-1]
            features['volume_trend_5d'] = self.calculate_volume_trend(daily_data.tail(5))
            
            # ê°€ê²© ëª¨ë©˜í…€
            features['price_momentum_5d'] = (daily_data['stck_clpr'].iloc[-1] - daily_data['stck_clpr'].iloc[-6]) / daily_data['stck_clpr'].iloc[-6]
            features['price_momentum_20d'] = (daily_data['stck_clpr'].iloc[-1] - daily_data['stck_clpr'].iloc[-21]) / daily_data['stck_clpr'].iloc[-21]
            
            return features
            
        except Exception as e:
            logger.error(f"ì¼ë´‰ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    def calculate_volume_trend(self, data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ íŠ¸ë Œë“œ ê³„ì‚°"""
        try:
            if len(data) < 2:
                return 0.0
            
            volumes = data['volume'] if 'volume' in data.columns else data['acml_vol']
            x = np.arange(len(volumes))
            y = volumes.values
            
            # ì„ í˜• íšŒê·€ë¡œ íŠ¸ë Œë“œ ê³„ì‚°
            slope = np.polyfit(x, y, 1)[0]
            return slope / volumes.mean()  # ì •ê·œí™”
            
        except:
            return 0.0
    
    def calculate_rsi(self, prices: pd.Series, period: int = 14) -> float:
        """RSI ê³„ì‚°"""
        try:
            if len(prices) < period + 1:
                return 50.0
            
            delta = prices.diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            
            return rsi.iloc[-1] if not pd.isna(rsi.iloc[-1]) else 50.0
            
        except:
            return 50.0

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    collector = MLDataCollector()
    
    # ìµœê·¼ 2ì£¼ê°„ ë°ì´í„° ìˆ˜ì§‘
    end_date = now_kst().strftime("%Y%m%d")
    start_date = (now_kst() - timedelta(days=14)).strftime("%Y%m%d")
    
    logger.info(f"ğŸš€ ML í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date}")
    
    # í•™ìŠµ ë°ì´í„° ìˆ˜ì§‘
    training_data = collector.collect_ml_training_data(start_date, end_date)
    
    if not training_data.empty:
        # ê²°ê³¼ ì €ì¥
        output_file = f"trade_analysis/ml_training_data_{start_date}_{end_date}.pkl"
        with open(output_file, 'wb') as f:
            pickle.dump(training_data, f)
        
        logger.info(f"âœ… í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_file}")
        logger.info(f"ğŸ“Š ì´ {len(training_data)}ê°œ ìƒ˜í”Œ, ìŠ¹ë¥ : {training_data['is_win'].mean():.2%}")
    else:
        logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

if __name__ == "__main__":
    main()
