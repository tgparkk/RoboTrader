"""
ì¼ë´‰ ê¸°ë°˜ íŒ¨í„´ í•„í„°ë§ ì‹œìŠ¤í…œ
ë¶„ì„ëœ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ìŠ¹ë¦¬ í™•ë¥ ì„ ë†’ì´ëŠ” í•„í„°ë§ ë¡œì§ êµ¬í˜„
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
import logging
from dataclasses import dataclass
from pathlib import Path
import pickle
import json

from utils.logger import setup_logger
from utils.korean_time import now_kst


@dataclass
class FilterResult:
    """í•„í„°ë§ ê²°ê³¼"""
    passed: bool
    score: float
    reason: str
    details: Dict[str, Any]


class DailyPatternFilter:
    """ì¼ë´‰ ê¸°ë°˜ íŒ¨í„´ í•„í„°"""
    
    def __init__(self, logger=None):
        self.logger = logger or setup_logger(__name__)
        self.filter_rules = {}
        self.feature_weights = {}
        self.load_filter_config()
    
    def load_filter_config(self, config_file: str = "daily_pattern_analysis.json"):
        """í•„í„° ì„¤ì • ë¡œë“œ"""
        try:
            if Path(config_file).exists():
                with open(config_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # íŠ¹ì„± ë¶„ì„ ê²°ê³¼ì—ì„œ í•„í„° ê·œì¹™ ìƒì„±
                if 'feature_analysis' in data:
                    self._create_filter_rules_from_analysis(data['feature_analysis'])
                
                self.logger.info(f"âœ… í•„í„° ì„¤ì • ë¡œë“œ ì™„ë£Œ: {len(self.filter_rules)}ê°œ ê·œì¹™")
            else:
                self.logger.warning(f"ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {config_file}")
                self._create_default_filter_rules()
                
        except Exception as e:
            self.logger.error(f"í•„í„° ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
            self._create_default_filter_rules()
    
    def _create_filter_rules_from_analysis(self, feature_analysis: Dict[str, Any]):
        """ë¶„ì„ ê²°ê³¼ì—ì„œ í•„í„° ê·œì¹™ ìƒì„±"""
        try:
            # ìƒìœ„ íŠ¹ì„±ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ í•„í„° ê·œì¹™ ìƒì„±
            sorted_features = sorted(
                feature_analysis.items(),
                key=lambda x: x[1]['normalized_weight'],
                reverse=True
            )
            
            for feature, analysis in sorted_features[:10]:  # ìƒìœ„ 10ê°œ íŠ¹ì„±ë§Œ ì‚¬ìš©
                if not analysis['significance']:
                    continue
                
                win_mean = analysis['win_mean']
                win_std = analysis['win_std']
                difference = analysis['difference']
                weight = analysis['normalized_weight']
                
                # í•„í„° ì„ê³„ê°’ ì„¤ì •
                if difference > 0:
                    # ìŠ¹ë¦¬ íŒ¨í„´ì´ ë” ë†’ì€ ê°’ì„ ê°€ì§
                    threshold = win_mean - 0.5 * win_std
                    condition = "greater_than"
                else:
                    # ìŠ¹ë¦¬ íŒ¨í„´ì´ ë” ë‚®ì€ ê°’ì„ ê°€ì§
                    threshold = win_mean + 0.5 * win_std
                    condition = "less_than"
                
                self.filter_rules[feature] = {
                    'threshold': threshold,
                    'condition': condition,
                    'weight': weight,
                    'description': f"{feature}: {condition} {threshold:.3f}",
                    'win_mean': win_mean,
                    'loss_mean': analysis['loss_mean'],
                    'difference': difference
                }
                
        except Exception as e:
            self.logger.error(f"í•„í„° ê·œì¹™ ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _create_default_filter_rules(self):
        """ê¸°ë³¸ í•„í„° ê·œì¹™ ìƒì„±"""
        # ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê¸°ë³¸ ê·œì¹™ë“¤
        self.filter_rules = {
            'consecutive_down_days': {
                'threshold': 0.5,
                'condition': 'greater_than',
                'weight': 1.0,
                'description': "ì—°ì† í•˜ë½ì¼: 0.5ì¼ ì´ìƒ",
                'win_mean': 0.769,
                'loss_mean': 0.538,
                'difference': 0.231
            },
            'gap_magnitude': {
                'threshold': 0.8,
                'condition': 'less_than',
                'weight': 0.663,
                'description': "ê°­ í¬ê¸°: 0.8% ë¯¸ë§Œ",
                'win_mean': 0.794,
                'loss_mean': 0.964,
                'difference': -0.170
            },
            'volatility_10d': {
                'threshold': 7.0,
                'condition': 'less_than',
                'weight': 0.342,
                'description': "10ì¼ ë³€ë™ì„±: 7.0% ë¯¸ë§Œ",
                'win_mean': 6.606,
                'loss_mean': 6.896,
                'difference': -0.291
            },
            'trend_strength_5d': {
                'threshold': 2.0,
                'condition': 'greater_than',
                'weight': 0.295,
                'description': "5ì¼ ì¶”ì„¸ê°•ë„: 2.0% ì´ìƒ",
                'win_mean': 2.835,
                'loss_mean': 2.638,
                'difference': 0.197
            },
            'support_resistance_ratio': {
                'threshold': 0.7,
                'condition': 'greater_than',
                'weight': 0.490,
                'description': "ì§€ì§€/ì €í•­ ë¹„ìœ¨: 0.7 ì´ìƒ",
                'win_mean': 0.708,
                'loss_mean': 0.732,
                'difference': -0.023
            }
        }
        
        self.logger.info(f"âœ… ê¸°ë³¸ í•„í„° ê·œì¹™ ìƒì„±: {len(self.filter_rules)}ê°œ")
    
    def load_daily_data(self, stock_code: str, date_str: str) -> Optional[pd.DataFrame]:
        """ì¼ë´‰ ë°ì´í„° ë¡œë“œ"""
        try:
            daily_cache_dir = Path("cache/daily_data")
            daily_file = daily_cache_dir / f"{stock_code}_daily.pkl"
            
            if not daily_file.exists():
                return None
                
            with open(daily_file, 'rb') as f:
                data = pickle.load(f)
            
            # ì»¬ëŸ¼ëª… ì •ë¦¬ ë° ë°ì´í„° íƒ€ì… ë³€í™˜
            if 'stck_bsop_date' in data.columns:
                data['date'] = pd.to_datetime(data['stck_bsop_date'])
            if 'stck_clpr' in data.columns:
                data['close'] = pd.to_numeric(data['stck_clpr'], errors='coerce')
            if 'stck_oprc' in data.columns:
                data['open'] = pd.to_numeric(data['stck_oprc'], errors='coerce')
            if 'stck_hgpr' in data.columns:
                data['high'] = pd.to_numeric(data['stck_hgpr'], errors='coerce')
            if 'stck_lwpr' in data.columns:
                data['low'] = pd.to_numeric(data['stck_lwpr'], errors='coerce')
            if 'acml_vol' in data.columns:
                data['volume'] = pd.to_numeric(data['acml_vol'], errors='coerce')
                
            return data.sort_values('date').reset_index(drop=True)
            
        except Exception as e:
            self.logger.debug(f"ì¼ë´‰ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨ {stock_code}: {e}")
            return None
    
    def extract_daily_features(self, daily_data: pd.DataFrame, signal_date: str) -> Dict[str, float]:
        """ì¼ë´‰ ë°ì´í„°ì—ì„œ íŠ¹ì„± ì¶”ì¶œ (íŒ¨í„´ ë¶„ì„ê¸°ì™€ ë™ì¼í•œ ë¡œì§)"""
        features = {}
        
        try:
            if daily_data is None or daily_data.empty:
                return features
            
            # ì‹ í˜¸ ë‚ ì§œ ì´ì „ ë°ì´í„°ë§Œ ì‚¬ìš©
            signal_dt = pd.to_datetime(signal_date)
            historical_data = daily_data[daily_data['date'] < signal_dt].copy()
            
            if len(historical_data) < 5:
                return features
            
            # ìµœê·¼ 5ì¼, 10ì¼, 20ì¼ ë°ì´í„°
            recent_5d = historical_data.tail(5)
            recent_10d = historical_data.tail(10)
            recent_20d = historical_data.tail(20)
            
            # 1. ê°€ê²© ëª¨ë©˜í…€ íŠ¹ì„±
            features['price_momentum_5d'] = self._calculate_price_momentum(recent_5d)
            features['price_momentum_10d'] = self._calculate_price_momentum(recent_10d)
            features['price_momentum_20d'] = self._calculate_price_momentum(recent_20d)
            
            # 2. ê±°ë˜ëŸ‰ íŠ¹ì„±
            features['volume_ratio_5d'] = self._calculate_volume_ratio(recent_5d)
            features['volume_ratio_10d'] = self._calculate_volume_ratio(recent_10d)
            features['volume_ratio_20d'] = self._calculate_volume_ratio(recent_20d)
            
            # 3. ë³€ë™ì„± íŠ¹ì„±
            features['volatility_5d'] = self._calculate_volatility(recent_5d)
            features['volatility_10d'] = self._calculate_volatility(recent_10d)
            features['volatility_20d'] = self._calculate_volatility(recent_20d)
            
            # 4. ì¶”ì„¸ íŠ¹ì„±
            features['trend_strength_5d'] = self._calculate_trend_strength(recent_5d)
            features['trend_strength_10d'] = self._calculate_trend_strength(recent_10d)
            features['trend_strength_20d'] = self._calculate_trend_strength(recent_20d)
            
            # 5. ì§€ì§€/ì €í•­ íŠ¹ì„±
            features['support_resistance_ratio'] = self._calculate_support_resistance_ratio(historical_data)
            
            # 6. ì—°ì† ìƒìŠ¹/í•˜ë½ íŠ¹ì„±
            features['consecutive_up_days'] = self._calculate_consecutive_days(recent_10d, 'up')
            features['consecutive_down_days'] = self._calculate_consecutive_days(recent_10d, 'down')
            
            # 7. ê°­ íŠ¹ì„±
            features['gap_frequency'] = self._calculate_gap_frequency(recent_10d)
            features['gap_magnitude'] = self._calculate_gap_magnitude(recent_10d)
            
        except Exception as e:
            self.logger.debug(f"ì¼ë´‰ íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return features
    
    def _calculate_price_momentum(self, data: pd.DataFrame) -> float:
        """ê°€ê²© ëª¨ë©˜í…€ ê³„ì‚°"""
        if len(data) < 2:
            return 0.0
        
        start_price = data['close'].iloc[0]
        end_price = data['close'].iloc[-1]
        
        if start_price == 0:
            return 0.0
        
        return (end_price - start_price) / start_price * 100
    
    def _calculate_volume_ratio(self, data: pd.DataFrame) -> float:
        """ê±°ë˜ëŸ‰ ë¹„ìœ¨ ê³„ì‚° (í‰ê·  ëŒ€ë¹„)"""
        if len(data) < 2:
            return 1.0
        
        recent_volume = data['volume'].iloc[-1]
        avg_volume = data['volume'].mean()
        
        if avg_volume == 0:
            return 1.0
        
        return recent_volume / avg_volume
    
    def _calculate_volatility(self, data: pd.DataFrame) -> float:
        """ë³€ë™ì„± ê³„ì‚° (ì¼ì¼ ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨)"""
        if len(data) < 2:
            return 0.0
        
        returns = data['close'].pct_change().dropna()
        return returns.std() * 100
    
    def _calculate_trend_strength(self, data: pd.DataFrame) -> float:
        """ì¶”ì„¸ ê°•ë„ ê³„ì‚° (ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°)"""
        if len(data) < 3:
            return 0.0
        
        x = np.arange(len(data))
        y = data['close'].values
        
        # ì„ í˜• íšŒê·€
        coeffs = np.polyfit(x, y, 1)
        slope = coeffs[0]
        
        # ì •ê·œí™” (ê°€ê²© ëŒ€ë¹„)
        avg_price = data['close'].mean()
        if avg_price == 0:
            return 0.0
        
        return (slope / avg_price) * 100
    
    def _calculate_support_resistance_ratio(self, data: pd.DataFrame) -> float:
        """ì§€ì§€/ì €í•­ ë¹„ìœ¨ ê³„ì‚°"""
        if len(data) < 10:
            return 0.5
        
        recent_20d = data.tail(20)
        current_price = recent_20d['close'].iloc[-1]
        
        # ìµœê·¼ 20ì¼ ê³ ê°€/ì €ê°€ ë²”ìœ„ì—ì„œ í˜„ì¬ê°€ ìœ„ì¹˜
        high_20d = recent_20d['high'].max()
        low_20d = recent_20d['low'].min()
        
        if high_20d == low_20d:
            return 0.5
        
        return (current_price - low_20d) / (high_20d - low_20d)
    
    def _calculate_consecutive_days(self, data: pd.DataFrame, direction: str) -> int:
        """ì—°ì† ìƒìŠ¹/í•˜ë½ ì¼ìˆ˜ ê³„ì‚°"""
        if len(data) < 2:
            return 0
        
        consecutive = 0
        for i in range(len(data) - 1, 0, -1):
            if direction == 'up' and data['close'].iloc[i] > data['close'].iloc[i-1]:
                consecutive += 1
            elif direction == 'down' and data['close'].iloc[i] < data['close'].iloc[i-1]:
                consecutive += 1
            else:
                break
        
        return consecutive
    
    def _calculate_gap_frequency(self, data: pd.DataFrame) -> float:
        """ê°­ ë¹ˆë„ ê³„ì‚°"""
        if len(data) < 2:
            return 0.0
        
        gaps = 0
        for i in range(1, len(data)):
            prev_close = data['close'].iloc[i-1]
            curr_open = data['open'].iloc[i]
            
            # ê°­ í¬ê¸°ê°€ 1% ì´ìƒì¸ ê²½ìš°
            if abs(curr_open - prev_close) / prev_close > 0.01:
                gaps += 1
        
        return gaps / (len(data) - 1)
    
    def _calculate_gap_magnitude(self, data: pd.DataFrame) -> float:
        """ê°­ í¬ê¸° ê³„ì‚°"""
        if len(data) < 2:
            return 0.0
        
        gap_magnitudes = []
        for i in range(1, len(data)):
            prev_close = data['close'].iloc[i-1]
            curr_open = data['open'].iloc[i]
            
            if prev_close != 0:
                gap_mag = (curr_open - prev_close) / prev_close * 100
                gap_magnitudes.append(gap_mag)
        
        return np.mean(gap_magnitudes) if gap_magnitudes else 0.0
    
    def apply_filter(self, stock_code: str, signal_date: str, signal_time: str) -> FilterResult:
        """ì¼ë´‰ ê¸°ë°˜ í•„í„° ì ìš©"""
        try:
            # ì¼ë´‰ ë°ì´í„° ë¡œë“œ
            daily_data = self.load_daily_data(stock_code, signal_date)
            if daily_data is None:
                return FilterResult(
                    passed=False,
                    score=0.0,
                    reason="ì¼ë´‰ ë°ì´í„° ì—†ìŒ",
                    details={}
                )
            
            # íŠ¹ì„± ì¶”ì¶œ
            features = self.extract_daily_features(daily_data, signal_date)
            if not features:
                return FilterResult(
                    passed=False,
                    score=0.0,
                    reason="íŠ¹ì„± ì¶”ì¶œ ì‹¤íŒ¨",
                    details={}
                )
            
            # í•„í„° ê·œì¹™ ì ìš©
            passed_rules = 0
            total_rules = 0
            total_score = 0.0
            details = {}
            
            for feature, rule in self.filter_rules.items():
                if feature not in features:
                    continue
                
                total_rules += 1
                feature_value = features[feature]
                threshold = rule['threshold']
                condition = rule['condition']
                weight = rule['weight']
                
                # ì¡°ê±´ í™•ì¸
                if condition == 'greater_than':
                    passed = feature_value > threshold
                elif condition == 'less_than':
                    passed = feature_value < threshold
                else:
                    passed = False
                
                if passed:
                    passed_rules += 1
                    total_score += weight
                
                details[feature] = {
                    'value': feature_value,
                    'threshold': threshold,
                    'condition': condition,
                    'passed': passed,
                    'weight': weight
                }
            
            # ìµœì¢… íŒì •
            pass_rate = passed_rules / total_rules if total_rules > 0 else 0
            min_pass_rate = 0.6  # 60% ì´ìƒì˜ ê·œì¹™ì„ í†µê³¼í•´ì•¼ í•¨
            
            passed = pass_rate >= min_pass_rate
            reason = f"í†µê³¼ìœ¨: {pass_rate:.1%} ({passed_rules}/{total_rules})"
            
            if not passed:
                reason += f" (ìµœì†Œ ìš”êµ¬: {min_pass_rate:.1%})"
            
            return FilterResult(
                passed=passed,
                score=total_score,
                reason=reason,
                details=details
            )
            
        except Exception as e:
            self.logger.error(f"í•„í„° ì ìš© ì‹¤íŒ¨ {stock_code}: {e}")
            return FilterResult(
                passed=False,
                score=0.0,
                reason=f"í•„í„° ì˜¤ë¥˜: {str(e)[:50]}",
                details={}
            )
    
    def get_filter_summary(self) -> Dict[str, Any]:
        """í•„í„° ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        return {
            'total_rules': len(self.filter_rules),
            'rules': self.filter_rules,
            'description': "ì¼ë´‰ ê¸°ë°˜ íŒ¨í„´ í•„í„°ë§ ì‹œìŠ¤í…œ"
        }


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    filter_system = DailyPatternFilter()
    
    # í•„í„° ìš”ì•½ ì¶œë ¥
    summary = filter_system.get_filter_summary()
    print("ğŸ¯ ì¼ë´‰ ê¸°ë°˜ íŒ¨í„´ í•„í„°ë§ ì‹œìŠ¤í…œ")
    print("=" * 50)
    print(f"ì´ ê·œì¹™ ìˆ˜: {summary['total_rules']}")
    print("\nğŸ“‹ í•„í„° ê·œì¹™:")
    
    for feature, rule in summary['rules'].items():
        print(f"â€¢ {rule['description']} (ê°€ì¤‘ì¹˜: {rule['weight']:.3f})")
        print(f"  ìŠ¹ë¦¬ í‰ê· : {rule['win_mean']:.3f}, íŒ¨ë°° í‰ê· : {rule['loss_mean']:.3f}")
        print(f"  ì°¨ì´: {rule['difference']:+.3f}")
        print()


if __name__ == "__main__":
    main()
